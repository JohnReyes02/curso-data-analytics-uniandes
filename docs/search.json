[
  {
    "objectID": "practica1_Ecopetrol.html",
    "href": "practica1_Ecopetrol.html",
    "title": "Bienvenido a la práctica de analítica de datos con Jupyter Notebook",
    "section": "",
    "text": "Sesión 1 : Analítica descriptiva de datos",
    "crumbs": [
      "Talleres",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bienvenido a la práctica de analítica de datos con Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "practica1_Ecopetrol.html#ecopetrol---universidad-de-los-andes",
    "href": "practica1_Ecopetrol.html#ecopetrol---universidad-de-los-andes",
    "title": "Bienvenido a la práctica de analítica de datos con Jupyter Notebook",
    "section": "Ecopetrol - Universidad de los Andes",
    "text": "Ecopetrol - Universidad de los Andes\nEsta primera práctica se realizará sobre los datos obtenidos de la página https://insideairbnb.com/  para la ciudad de Albany\n\nPreparación del ambiente de trabajo\n\nCargue de librerías\nAntes de realizar un análisis, se debe verificar que se cuenta con las librerías requeridas intaladas.  En este taller iniciamos con las librerías básicas.  Sin embargo, en cualquier momento se puede realizar la instalación y cargue de una nueva librería.  Para la instalación de una nueva librería puede utilizar el comando ‘conda install’ de Anaconda.\n\nimport os, sys\nimport numpy as np\nimport pandas as pd\n\n\n\n\nLectura de los datos\nLectura desde carpeta local de un archivo en formato csv  Ingrese a la carpeta compartida en Onedrive TALLER 1 y descargue los archivos: listings.csv y listings.xlsx  Configuración del directorio:  1. Copie la ruta en donde guardó el archivo\n\n## Copie la ruta despues del comando %cd\n# %cd C:\\Users\\X1 Carbon\\OneDrive\\Documentos\\1_NEICON\\1_Proyectos\\2_Carpeta Tito\\Capacitación UniAndes_Ecopetrol\\Datsets\\Taller_1\nruta = './listings.csv'\n\n\n## Compado para cargar archivos en formato texto (csv)\ndata=pd.read_csv(ruta, sep=',')\n\n\n## Comando Para obtener una primera vista de la tabla\ndata.head(3)\n\n\n\n\n\n\n\n\nid\nname\nhost_id\nhost_name\nneighbourhood_group\nneighbourhood\nlatitude\nlongitude\nroom_type\nprice\nminimum_nights\nnumber_of_reviews\nlast_review\nreviews_per_month\ncalculated_host_listings_count\navailability_365\nnumber_of_reviews_ltm\nlicense\n\n\n\n\n0\n621960198566758900\nThe Historic Jesse Buel Farmhouse w/ Heated Pool\n382970529\nThomas\nNaN\nFOURTEENTH WARD\n42.66762\n-73.79919\nEntire home/apt\n882.0\n1\n15\n2025-02-06\n0.47\n12\n330\n8\nNaN\n\n\n1\n932642358896439621\nStylish top floor apt w/parking\n232967878\nDiana\nNaN\nTHIRTEENTH WARD\n42.67224\n-73.79301\nEntire home/apt\n106.0\n1\n37\n2025-02-15\n1.88\n23\n86\n26\nNaN\n\n\n2\n53567589\nPrivate Garden Apt in Downtown Albany|Pets All...\n433096110\nBrian\nNaN\nSIXTH WARD\n42.65204\n-73.76655\nEntire home/apt\n99.0\n1\n251\n2025-02-23\n6.40\n4\n341\n73\nNaN\n\n\n\n\n\n\n\n\nLectura desde carpeta local de un archivo en formato excel\n\n## Comando para cargue d archivos en formato Excel\nruta = './listings.xlsx'\ndata=pd.read_excel(ruta)\ndata.head(4)\n\n\n\n\n\n\n\n\nid\nname\nhost_id\nhost_name\nneighbourhood_group\nneighbourhood\nlatitude\nlongitude\nroom_type\nprice\nminimum_nights\nnumber_of_reviews\nlast_review\nreviews_per_month\ncalculated_host_listings_count\navailability_365\nnumber_of_reviews_ltm\nlicense\n\n\n\n\n0\n621960198566758912\nThe Historic Jesse Buel Farmhouse w/ Heated Pool\n382970529\nThomas\nNaN\nFOURTEENTH WARD\n42.66762\n-73.79919\nEntire home/apt\n882.0\n1\n15\n2025-02-06\n0.47\n12\n330\n8\nNaN\n\n\n1\n932642358896439680\nStylish top floor apt w/parking\n232967878\nDiana\nNaN\nTHIRTEENTH WARD\n42.67224\n-73.79301\nEntire home/apt\n106.0\n1\n37\n2025-02-15\n1.88\n23\n86\n26\nNaN\n\n\n2\n53567589\nPrivate Garden Apt in Downtown Albany|Pets All...\n433096110\nBrian\nNaN\nSIXTH WARD\n42.65204\n-73.76655\nEntire home/apt\n99.0\n1\n251\n2025-02-23\n6.40\n4\n341\n73\nNaN\n\n\n3\n20671966\nThe Metropolitan\n98744672\nBela\nNaN\nNINTH WARD\n42.65532\n-73.78244\nEntire home/apt\n58.0\n2\n46\n2025-01-19\n0.51\n8\n248\n7\nNaN\n\n\n\n\n\n\n\nComo se puede observar en la vista anterior, la primera columna no tiene nombre, esto es por que el data frame de pandas asigna un índice, el cual nos puede ayudar a realizar algunas consultas posteriormente   Una vez se han cargado los datos se debe realizar un primer diagnóstico.  Identifique cuál es el tipo de variables que contiene el archivo, si la herramienta cargó correctamente los datos, la cantidad, formatos, valores etc.   Con su equipo haga una breve descripción del dataset cargado. Utilice los siguientes comandos para hacer la exploración\n\n#Relaciona la cantidad de registros y variables que contiene el dataset\ndata.shape\n\n(424, 18)\n\n\n\n#Lista todas las variables que contiene el dataset y especifica el tipo de dato\ndata.dtypes\n\nid                                         int64\nname                                      object\nhost_id                                    int64\nhost_name                                 object\nneighbourhood_group                      float64\nneighbourhood                             object\nlatitude                                 float64\nlongitude                                float64\nroom_type                                 object\nprice                                    float64\nminimum_nights                             int64\nnumber_of_reviews                          int64\nlast_review                       datetime64[ns]\nreviews_per_month                        float64\ncalculated_host_listings_count             int64\navailability_365                           int64\nnumber_of_reviews_ltm                      int64\nlicense                                  float64\ndtype: object\n\n\n\n#Exploración de variables continuas\n#Vamos a filtras las variables a analizar\n#Para el ejercicio complemente con las variables faltantes que puedan ser de interés.\n\ndata_continuas=data.loc[:, ['price','minimum_nights', 'availability_365']]\ndata_continuas.head()\n\n\n\n\n\n\n\n\nprice\nminimum_nights\navailability_365\n\n\n\n\n0\n882.0\n1\n330\n\n\n1\n106.0\n1\n86\n\n\n2\n99.0\n1\n341\n\n\n3\n58.0\n2\n248\n\n\n4\n50.0\n2\n340\n\n\n\n\n\n\n\n\n#Cómo se comporta la variable precio - analice el resultado\ndata_continuas['price'].describe()\n\ncount    374.000000\nmean     110.042781\nstd       86.746145\nmin       24.000000\n25%       68.000000\n50%       93.000000\n75%      122.750000\nmax      882.000000\nName: price, dtype: float64\n\n\n\n# Ahora vamos a generar las estadísticas descriptivas para todas las variables a la vez.\n# Analice el resultado\n\nvariables_continuas = ['price','minimum_nights', 'availability_365']\nestadisticas = data[variables_continuas].describe().T\n\n# Mostramos las estadísticas\nprint(\"Estadísticas descriptivas\")\nprint(estadisticas)\n\nEstadísticas descriptivas\n                  count        mean         std   min     25%    50%     75%  \\\nprice             374.0  110.042781   86.746145  24.0   68.00   93.0  122.75   \nminimum_nights    424.0    5.693396    9.627107   1.0    1.00    2.0    3.00   \navailability_365  424.0  233.261792  119.275432   0.0  119.75  268.0  341.25   \n\n                    max  \nprice             882.0  \nminimum_nights     70.0  \navailability_365  365.0  \n\n\n\ndata_continuas.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 424 entries, 0 to 423\nData columns (total 3 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   price             374 non-null    float64\n 1   minimum_nights    424 non-null    int64  \n 2   availability_365  424 non-null    int64  \ndtypes: float64(1), int64(2)\nmemory usage: 10.1 KB\n\n\n\n# Ahora vamos a analizar el comportamiento de manera gráfica para lo cual cargamos la librería\nimport matplotlib.pyplot as plt\n\n# Histogramas de frecuencia\ndata[variables_continuas].hist('price', figsize=(3, 3), bins=20)\nplt.tight_layout()\nplt.show()\n\n#Analiza el resultado y explora el código para mejorar el gráfico\n\n\n\n\n\n\n\n\n\n#Ahora probemos otra sintáxis\n\ndata[data['price'] &lt;= 200]['price'].hist(figsize=(3, 3), bins=10)\n\nplt.title('Histograma de price (&lt;= 200)')\nplt.xlabel('Price')\nplt.ylabel('Frecuencia')\nplt.tight_layout()\nplt.show()\n\n#Analiza el resultado y comparte tus conclusiones.\n#Compara las dos sintaxis, que observas?\n\n\n\n\n\n\n\n\n\ndata_continuas2=data.loc[:, ['price','neighbourhood']]\ndata_continuas2.head(10)\n\n\n\n\n\n\n\n\nprice\nneighbourhood\n\n\n\n\n0\n882.0\nFOURTEENTH WARD\n\n\n1\n106.0\nTHIRTEENTH WARD\n\n\n2\n99.0\nSIXTH WARD\n\n\n3\n58.0\nNINTH WARD\n\n\n4\n50.0\nNINTH WARD\n\n\n5\n93.0\nSIXTH WARD\n\n\n6\n156.0\nFOURTEENTH WARD\n\n\n7\n142.0\nFOURTEENTH WARD\n\n\n8\n96.0\nSIXTH WARD\n\n\n9\n88.0\nSIXTH WARD\n\n\n\n\n\n\n\n\n# Calculamos la frecuencia por cada valor que toma la variable\nfrecuencia_neighbourhood = data_continuas2['neighbourhood'].value_counts()\nprint(frecuencia_neighbourhood)\n\nneighbourhood\nSIXTH WARD         96\nSECOND WARD        51\nTENTH WARD         44\nTHIRTEENTH WARD    42\nTHIRD WARD         39\nNINTH WARD         32\nFOURTEENTH WARD    24\nFIFTEENTH WARD     18\nSEVENTH WARD       16\nELEVENTH WARD      15\nFOURTH WARD        14\nEIGHTH WARD        11\nFIRST WARD          9\nFIFTH WARD          7\nTWELFTH WARD        6\nName: count, dtype: int64\n\n\n\nplot_frec_abs = data_continuas2['neighbourhood'].value_counts().plot(kind='bar', title='Frecuencia de neighbourhood')\n\nplt.xlabel('neighbourhood')\nplt.ylabel('Frecuencia absoluta')\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Ahora vamos a realizar el análisis con los boxplot\ndata_continuas2.boxplot('price',by=\"neighbourhood\", figsize=(5,5))\nplt.xticks(rotation=90)\nplt.show()",
    "crumbs": [
      "Talleres",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bienvenido a la práctica de analítica de datos con Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "practica1_Ecopetrol.html#vamos-a-revisar-lo-que-hemos-aprendido-hasta-acá",
    "href": "practica1_Ecopetrol.html#vamos-a-revisar-lo-que-hemos-aprendido-hasta-acá",
    "title": "Bienvenido a la práctica de analítica de datos con Jupyter Notebook",
    "section": "Vamos a revisar lo que hemos aprendido hasta acá",
    "text": "Vamos a revisar lo que hemos aprendido hasta acá\n\n¿Qué información nos proporcionan las estadísticas descriptivas?\n\n\n¿Qué información nos proporcionan los gráficos?\n\n\nCómo cientifico de datos cuál es tu recomendación del método a utilizar para analizar variables continuas?\n\n#Ahora vamos a explorar un tipo de gráfico que combina los dos métodos.\ndata[data['price']&lt;=100].boxplot('price')\n\nplt.title('Boxplot de Price (&lt;= 100)')\nplt.ylabel('Price')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nAhora vamos a analizar las variables categóricas\n\n#Seleccionamos en el dataset las variables categóricas de interés\nvariables_categoricas = ['neighbourhood','room_type']\n\n# Calculamos la frecuencia por cada valor que toma la variable\nfrecuencia_neighbourhood = data['room_type'].value_counts()\nprint(frecuencia_neighbourhood)\n\nroom_type\nEntire home/apt    308\nPrivate room       116\nName: count, dtype: int64\n\n\n\nplot_frec_abs = data['room_type'].value_counts().plot(kind='bar', title='Frecuencia de neighbourhood')\n\nplt.xlabel('room_type')\nplt.ylabel('Frecuencia absoluta')\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nReplique el ejercicio para la vaiable room_type\n\n#Esta sintaxis permite generar la tabla de frecuencias para las dos variables a la vez\n\nfor col in variables_categoricas:\n    print(f\"Frecuencia de valores en la variable '{col}':\")\n    print(data[col].value_counts())\n    print(\"\\n\" + \"-\"*40 + \"\\n\")\n\nFrecuencia de valores en la variable 'neighbourhood':\nneighbourhood\nSIXTH WARD         96\nSECOND WARD        51\nTENTH WARD         44\nTHIRTEENTH WARD    42\nTHIRD WARD         39\nNINTH WARD         32\nFOURTEENTH WARD    24\nFIFTEENTH WARD     18\nSEVENTH WARD       16\nELEVENTH WARD      15\nFOURTH WARD        14\nEIGHTH WARD        11\nFIRST WARD          9\nFIFTH WARD          7\nTWELFTH WARD        6\nName: count, dtype: int64\n\n----------------------------------------\n\nFrecuencia de valores en la variable 'room_type':\nroom_type\nEntire home/apt    308\nPrivate room       116\nName: count, dtype: int64\n\n----------------------------------------\n\n\n\n\n#Ahora descubre que pasa con esta sintaxis\nfrecuencia_neighbourhood = data[variables_categoricas].value_counts()\nprint(frecuencia_neighbourhood)\n\nneighbourhood    room_type      \nSIXTH WARD       Entire home/apt    83\nSECOND WARD      Entire home/apt    45\nTHIRD WARD       Entire home/apt    33\nTENTH WARD       Private room       25\nTHIRTEENTH WARD  Entire home/apt    23\nTENTH WARD       Entire home/apt    19\nTHIRTEENTH WARD  Private room       19\nNINTH WARD       Entire home/apt    17\n                 Private room       15\nSEVENTH WARD     Entire home/apt    15\nFOURTEENTH WARD  Entire home/apt    14\nFIFTEENTH WARD   Entire home/apt    14\nSIXTH WARD       Private room       13\nFOURTH WARD      Entire home/apt    12\nFOURTEENTH WARD  Private room       10\nELEVENTH WARD    Private room        9\nFIRST WARD       Entire home/apt     9\nEIGHTH WARD      Entire home/apt     8\nSECOND WARD      Private room        6\nTHIRD WARD       Private room        6\nELEVENTH WARD    Entire home/apt     6\nFIFTH WARD       Entire home/apt     5\nTWELFTH WARD     Entire home/apt     5\nFIFTEENTH WARD   Private room        4\nEIGHTH WARD      Private room        3\nFOURTH WARD      Private room        2\nFIFTH WARD       Private room        2\nSEVENTH WARD     Private room        1\nTWELFTH WARD     Private room        1\nName: count, dtype: int64\n\n\n\n#Mejoremos la visualización, pero antes filtremos el dataset para simplificar el código\n\ndata_categoricas=data.loc[:, ['neighbourhood','room_type']]\n\nTabla = pd.crosstab(index=data_categoricas.neighbourhood,columns=data_categoricas[\"room_type\"])\nTabla\n\n# Se obtuvo el mismo resultado?\n\n\n\n\n\n\n\nroom_type\nEntire home/apt\nPrivate room\n\n\nneighbourhood\n\n\n\n\n\n\nEIGHTH WARD\n8\n3\n\n\nELEVENTH WARD\n6\n9\n\n\nFIFTEENTH WARD\n14\n4\n\n\nFIFTH WARD\n5\n2\n\n\nFIRST WARD\n9\n0\n\n\nFOURTEENTH WARD\n14\n10\n\n\nFOURTH WARD\n12\n2\n\n\nNINTH WARD\n17\n15\n\n\nSECOND WARD\n45\n6\n\n\nSEVENTH WARD\n15\n1\n\n\nSIXTH WARD\n83\n13\n\n\nTENTH WARD\n19\n25\n\n\nTHIRD WARD\n33\n6\n\n\nTHIRTEENTH WARD\n23\n19\n\n\nTWELFTH WARD\n5\n1\n\n\n\n\n\n\n\n\n\n# Agrupamos por la variable 'v' y contamos ocurrencias\nconteo = data_categoricas['room_type'].value_counts()\n\n# Creamos el gráfico de torta\nconteo.plot.pie(autopct='%1.1f%%', startangle=90, figsize=(6, 6))\n\n# Opcional: agregar título\nplt.title('Distribución de la variable Room Type')\n\n# Eliminar el eje Y que se añade por defecto\nplt.ylabel('')\n\n# Mostrar el gráfico\nplt.show()",
    "crumbs": [
      "Talleres",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bienvenido a la práctica de analítica de datos con Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "practica1_Ecopetrol.html#análisis-bivariado-variables-continuas-vs-variables-categóricas",
    "href": "practica1_Ecopetrol.html#análisis-bivariado-variables-continuas-vs-variables-categóricas",
    "title": "Bienvenido a la práctica de analítica de datos con Jupyter Notebook",
    "section": "Análisis bivariado (Variables continuas vs Variables categóricas)",
    "text": "Análisis bivariado (Variables continuas vs Variables categóricas)\nAhora vamos a integrar los dos tipos de variables en el análisis\n\n#Exploración de variables continuas y categórica a través de análisi bivariados.\n#Vamos a filtras las variables a analizar\n\ndata_bivariado=data.loc[:, ['price','minimum_nights', 'availability_365', 'room_type', 'neighbourhood']]\ndata_bivariado.head()\n\n\n\n\n\n\n\n\nprice\nminimum_nights\navailability_365\nroom_type\nneighbourhood\n\n\n\n\n0\n882.0\n1\n330\nEntire home/apt\nFOURTEENTH WARD\n\n\n1\n106.0\n1\n86\nEntire home/apt\nTHIRTEENTH WARD\n\n\n2\n99.0\n1\n341\nEntire home/apt\nSIXTH WARD\n\n\n3\n58.0\n2\n248\nEntire home/apt\nNINTH WARD\n\n\n4\n50.0\n2\n340\nPrivate room\nNINTH WARD\n\n\n\n\n\n\n\n\n#El siguiente código nos permite responder a la pregunta de ¿Cuál es el precio promedio de alquiler por tipo de habitación?\n\ndata_bivariado.pivot_table(values='price',columns='room_type',aggfunc=\"mean\").round(2)\n\n\n\n\n\n\n\nroom_type\nEntire home/apt\nPrivate room\n\n\n\n\nprice\n125.02\n69.56\n\n\n\n\n\n\n\n\n#Ahora vamos a ajustar la sintaxis para obtener distintas métricas para la misma variable\n\ndata_bivariado.pivot_table(values='price',columns='room_type',aggfunc=[\"mean\", \"median\", \"std\"]).round(2)\n\n\n\n\n\n\n\n\nmean\nmedian\nstd\n\n\nroom_type\nEntire home/apt\nPrivate room\nEntire home/apt\nPrivate room\nEntire home/apt\nPrivate room\n\n\n\n\nprice\n125.02\n69.56\n101.0\n56.0\n94.17\n40.98\n\n\n\n\n\n\n\n\n# Mejoremos la visualización\n\ntabla=data_bivariado.pivot_table(values='price',columns='room_type',aggfunc=['mean', 'median', 'std']).round(2)\ntabla_final = tabla.stack(level=1, future_stack=True).reset_index()\nprint(tabla_final)\n\n  level_0        room_type    mean  median    std\n0   price  Entire home/apt  125.02   101.0  94.17\n1   price     Private room   69.56    56.0  40.98\n\n\n\n# Ahora vamos a incluir más variables continuas\ntabla_multi = data_bivariado.pivot_table(\n    values=['price', 'minimum_nights', 'availability_365'],\n    index=['room_type', 'neighbourhood'],\n    aggfunc=['mean', 'median', 'std']\n).round(2)\n\nprint(tabla_multi)\n\n                                            mean                         \\\n                                availability_365 minimum_nights   price   \nroom_type       neighbourhood                                             \nEntire home/apt EIGHTH WARD               226.25           5.25  195.25   \n                ELEVENTH WARD             242.33           1.83  114.20   \n                FIFTEENTH WARD            317.93           5.64  221.50   \n                FIFTH WARD                245.20           2.00  106.00   \n                FIRST WARD                173.44           5.78  134.86   \n                FOURTEENTH WARD           240.50           3.00  180.07   \n                FOURTH WARD               230.83           4.42  118.57   \n                NINTH WARD                257.29           7.71  151.80   \n                SECOND WARD               214.76           2.42  125.55   \n                SEVENTH WARD              213.13           6.07  104.00   \n                SIXTH WARD                234.64           4.39   97.86   \n                TENTH WARD                223.00           1.79  157.35   \n                THIRD WARD                262.94          11.48   87.38   \n                THIRTEENTH WARD           204.57           5.74  148.71   \n                TWELFTH WARD              163.00           7.60  107.00   \nPrivate room    EIGHTH WARD               169.00           1.00   62.33   \n                ELEVENTH WARD             309.56           6.67   43.57   \n                FIFTEENTH WARD            203.50           2.50   42.00   \n                FIFTH WARD                364.50           8.00   93.00   \n                FOURTEENTH WARD           142.00           4.10   60.80   \n                FOURTH WARD               178.50           2.00   87.00   \n                NINTH WARD                235.27           1.60   62.79   \n                SECOND WARD               187.00           1.17   89.80   \n                SEVENTH WARD              248.00           1.00   50.00   \n                SIXTH WARD                277.00           1.77  125.40   \n                TENTH WARD                248.60          16.16   68.95   \n                THIRD WARD                256.17          10.50   51.80   \n                THIRTEENTH WARD           209.84           9.95   63.00   \n                TWELFTH WARD              268.00           2.00   54.00   \n\n                                          median                        \\\n                                availability_365 minimum_nights  price   \nroom_type       neighbourhood                                            \nEntire home/apt EIGHTH WARD                200.0            3.0  207.0   \n                ELEVENTH WARD              262.5            2.0  104.0   \n                FIFTEENTH WARD             334.0            1.0  181.5   \n                FIFTH WARD                 357.0            2.0  106.5   \n                FIRST WARD                 163.0            2.0  114.0   \n                FOURTEENTH WARD            256.0            1.0  123.5   \n                FOURTH WARD                284.5            1.0  104.0   \n                NINTH WARD                 250.0            2.0  101.0   \n                SECOND WARD                279.0            1.0  108.0   \n                SEVENTH WARD               252.0            2.0  106.5   \n                SIXTH WARD                 291.0            2.0   93.0   \n                TENTH WARD                 318.0            1.0  118.0   \n                THIRD WARD                 268.0            4.0   89.5   \n                THIRTEENTH WARD            207.0            2.0  109.0   \n                TWELFTH WARD               200.0            3.0  119.5   \nPrivate room    EIGHTH WARD                140.0            1.0   53.0   \n                ELEVENTH WARD              324.0            2.0   44.0   \n                FIFTEENTH WARD             230.5            2.5   41.0   \n                FIFTH WARD                 364.5            8.0   93.0   \n                FOURTEENTH WARD            109.0            1.0   59.5   \n                FOURTH WARD                178.5            2.0   87.0   \n                NINTH WARD                 266.0            2.0   53.0   \n                SECOND WARD                184.0            1.0   58.0   \n                SEVENTH WARD               248.0            1.0   50.0   \n                SIXTH WARD                 334.0            1.0  127.0   \n                TENTH WARD                 300.0           18.0   56.0   \n                THIRD WARD                 361.0            1.5   37.0   \n                THIRTEENTH WARD            239.0            3.0   56.0   \n                TWELFTH WARD               268.0            2.0   54.0   \n\n                                             std                         \n                                availability_365 minimum_nights   price  \nroom_type       neighbourhood                                            \nEntire home/apt EIGHTH WARD               120.56           4.80   48.03  \n                ELEVENTH WARD             121.40           0.75   21.64  \n                FIFTEENTH WARD             64.16          10.36  142.56  \n                FIFTH WARD                157.52           0.71   12.99  \n                FIRST WARD                131.35           9.31   63.71  \n                FOURTEENTH WARD            92.00           3.62  210.39  \n                FOURTH WARD               113.02           8.76   27.99  \n                NINTH WARD                 95.90          17.48  183.49  \n                SECOND WARD               129.41           3.47   65.36  \n                SEVENTH WARD              145.84           9.59   42.72  \n                SIXTH WARD                126.84           7.73   27.44  \n                TENTH WARD                140.31           1.44  109.35  \n                THIRD WARD                 90.84          12.33   18.06  \n                THIRTEENTH WARD           115.37          12.70  149.22  \n                TWELFTH WARD              112.21          11.41   32.09  \nPrivate room    EIGHTH WARD               182.24           0.00   16.17  \n                ELEVENTH WARD              51.03           7.81    9.07  \n                FIFTEENTH WARD            171.93           0.58    4.58  \n                FIFTH WARD                  0.71           9.90     NaN  \n                FOURTEENTH WARD            86.55           8.43    8.00  \n                FOURTH WARD                 0.71           1.41   24.04  \n                NINTH WARD                103.18           0.51   31.89  \n                SECOND WARD               146.21           0.41   63.58  \n                SEVENTH WARD                 NaN            NaN     NaN  \n                SIXTH WARD                113.72           1.54   66.57  \n                TENTH WARD                119.71          12.90   42.37  \n                THIRD WARD                166.69          14.35   24.36  \n                THIRTEENTH WARD           107.85          12.20   25.54  \n                TWELFTH WARD                 NaN            NaN     NaN  \n\n\n\n# Ahora vamos a realizar el análisis con los boxplot\ndata_bivariado.boxplot('price',by=\"room_type\", figsize=(5,5))\n\n\n\n\n\n\n\n\n\ndf_private_room= data[data['room_type'] == 'Private room']\ndf_private_room.head(5)\n\n\n\n\n\n\n\n\nid\nname\nhost_id\nhost_name\nneighbourhood_group\nneighbourhood\nlatitude\nlongitude\nroom_type\nprice\nminimum_nights\nnumber_of_reviews\nlast_review\nreviews_per_month\ncalculated_host_listings_count\navailability_365\nnumber_of_reviews_ltm\nlicense\n\n\n\n\n4\n24606880\nThe Western Suite\n98744672\nBela\nNaN\nNINTH WARD\n42.65431\n-73.78178\nPrivate room\n50.0\n2\n48\n2025-02-27\n0.62\n8\n340\n9\nNaN\n\n\n11\n937927979762952960\nHudson 4 at The Argus Hotel\n526358730\nArgus\nNaN\nTENTH WARD\n42.66043\n-73.77432\nPrivate room\n165.0\n1\n2\n2024-10-12\n0.33\n12\n300\n2\nNaN\n\n\n12\n937837897631191808\nHudson 2 at The Argus Hotel\n526358730\nArgus\nNaN\nSIXTH WARD\n42.65867\n-73.77479\nPrivate room\n165.0\n1\n2\n2023-12-31\n0.11\n12\n304\n0\nNaN\n\n\n15\n938271786418327552\nKnickerbocker 3 The Argus Hotel\n526358730\nArgus\nNaN\nSIXTH WARD\n42.65868\n-73.77333\nPrivate room\n243.0\n1\n0\nNaT\nNaN\n12\n340\n0\nNaN\n\n\n16\n937935210290408960\nHudson 5 at The Argus Hotel\n526358730\nArgus\nNaN\nSIXTH WARD\n42.65847\n-73.77272\nPrivate room\n161.0\n1\n5\n2024-12-29\n0.30\n12\n336\n4\nNaN",
    "crumbs": [
      "Talleres",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bienvenido a la práctica de analítica de datos con Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "practica1_Ecopetrol.html#bonus-track",
    "href": "practica1_Ecopetrol.html#bonus-track",
    "title": "Bienvenido a la práctica de analítica de datos con Jupyter Notebook",
    "section": "Bonus track",
    "text": "Bonus track\n\nMétricas disponibles en numpy para variables continuas\n\n\n📊 Estadísticas básicas\n\n\n\n\n\n\n\n\nMétrica\nDescripción\nEjemplo en aggfunc\n\n\n\n\nnp.mean\nMedia (promedio)\naggfunc=np.mean\n\n\nnp.sum\nSuma total\naggfunc=np.sum\n\n\nnp.min\nValor mínimo\naggfunc=np.min\n\n\nnp.max\nValor máximo\naggfunc=np.max\n\n\nnp.median\nMediana\naggfunc=np.median\n\n\nnp.std\nDesviación estándar\naggfunc=np.std\n\n\nnp.var\nVarianza\naggfunc=np.var       |",
    "crumbs": [
      "Talleres",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bienvenido a la práctica de analítica de datos con Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "Taller_1/practica1_Ecopetrol.html",
    "href": "Taller_1/practica1_Ecopetrol.html",
    "title": "Sesión 1: Analítica descriptiva de datos",
    "section": "",
    "text": "Preparación del ambiente de trabajo\nEsta primera práctica se realizará sobre los datos obtenidos de la página https://insideairbnb.com/  para la ciudad de Albany",
    "crumbs": [
      "Sesiones",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Sesión 1: Analítica descriptiva de datos</span>"
    ]
  },
  {
    "objectID": "Taller_1/practica1_Ecopetrol.html#ecopetrol---universidad-de-los-andes",
    "href": "Taller_1/practica1_Ecopetrol.html#ecopetrol---universidad-de-los-andes",
    "title": "Taller 1",
    "section": "Ecopetrol - Universidad de los Andes",
    "text": "Ecopetrol - Universidad de los Andes\nEsta primera práctica se realizará sobre los datos obtenidos de la página https://insideairbnb.com/  para la ciudad de Albany\n\nPreparación del ambiente de trabajo\n\nCargue de librerías\nAntes de realizar un análisis, se debe verificar que se cuenta con las librerías requeridas intaladas.  En este taller iniciamos con las librerías básicas.  Sin embargo, en cualquier momento se puede realizar la instalación y cargue de una nueva librería.  Para la instalación de una nueva librería puede utilizar el comando ‘conda install’ de Anaconda.\n\nimport os, sys\nimport numpy as np\nimport pandas as pd\n\n\n\n\nLectura de los datos\nLectura desde carpeta local de un archivo en formato csv  Ingrese a la carpeta compartida en Onedrive TALLER 1 y descargue los archivos: listings.csv y listings.xlsx  Configuración del directorio:  1. Copie la ruta en donde guardó el archivo\n\n## Copie la ruta despues del comando %cd\n# %cd C:\\Users\\X1 Carbon\\OneDrive\\Documentos\\1_NEICON\\1_Proyectos\\2_Carpeta Tito\\Capacitación UniAndes_Ecopetrol\\Datsets\\Taller_1\nruta = './listings.csv'\n\n\n## Compado para cargar archivos en formato texto (csv)\ndata=pd.read_csv(ruta, sep=',')\n\n\n## Comando Para obtener una primera vista de la tabla\ndata.head(3)\n\n\n\n\n\n\n\n\nid\nname\nhost_id\nhost_name\nneighbourhood_group\nneighbourhood\nlatitude\nlongitude\nroom_type\nprice\nminimum_nights\nnumber_of_reviews\nlast_review\nreviews_per_month\ncalculated_host_listings_count\navailability_365\nnumber_of_reviews_ltm\nlicense\n\n\n\n\n0\n621960198566758900\nThe Historic Jesse Buel Farmhouse w/ Heated Pool\n382970529\nThomas\nNaN\nFOURTEENTH WARD\n42.66762\n-73.79919\nEntire home/apt\n882.0\n1\n15\n2025-02-06\n0.47\n12\n330\n8\nNaN\n\n\n1\n932642358896439621\nStylish top floor apt w/parking\n232967878\nDiana\nNaN\nTHIRTEENTH WARD\n42.67224\n-73.79301\nEntire home/apt\n106.0\n1\n37\n2025-02-15\n1.88\n23\n86\n26\nNaN\n\n\n2\n53567589\nPrivate Garden Apt in Downtown Albany|Pets All...\n433096110\nBrian\nNaN\nSIXTH WARD\n42.65204\n-73.76655\nEntire home/apt\n99.0\n1\n251\n2025-02-23\n6.40\n4\n341\n73\nNaN\n\n\n\n\n\n\n\n\nLectura desde carpeta local de un archivo en formato excel\n\n## Comando para cargue d archivos en formato Excel\nruta = './listings.xlsx'\ndata=pd.read_excel(ruta)\ndata.head(4)\n\n\n\n\n\n\n\n\nid\nname\nhost_id\nhost_name\nneighbourhood_group\nneighbourhood\nlatitude\nlongitude\nroom_type\nprice\nminimum_nights\nnumber_of_reviews\nlast_review\nreviews_per_month\ncalculated_host_listings_count\navailability_365\nnumber_of_reviews_ltm\nlicense\n\n\n\n\n0\n621960198566758912\nThe Historic Jesse Buel Farmhouse w/ Heated Pool\n382970529\nThomas\nNaN\nFOURTEENTH WARD\n42.66762\n-73.79919\nEntire home/apt\n882.0\n1\n15\n2025-02-06\n0.47\n12\n330\n8\nNaN\n\n\n1\n932642358896439680\nStylish top floor apt w/parking\n232967878\nDiana\nNaN\nTHIRTEENTH WARD\n42.67224\n-73.79301\nEntire home/apt\n106.0\n1\n37\n2025-02-15\n1.88\n23\n86\n26\nNaN\n\n\n2\n53567589\nPrivate Garden Apt in Downtown Albany|Pets All...\n433096110\nBrian\nNaN\nSIXTH WARD\n42.65204\n-73.76655\nEntire home/apt\n99.0\n1\n251\n2025-02-23\n6.40\n4\n341\n73\nNaN\n\n\n3\n20671966\nThe Metropolitan\n98744672\nBela\nNaN\nNINTH WARD\n42.65532\n-73.78244\nEntire home/apt\n58.0\n2\n46\n2025-01-19\n0.51\n8\n248\n7\nNaN\n\n\n\n\n\n\n\nComo se puede observar en la vista anterior, la primera columna no tiene nombre, esto es por que el data frame de pandas asigna un índice, el cual nos puede ayudar a realizar algunas consultas posteriormente   Una vez se han cargado los datos se debe realizar un primer diagnóstico.  Identifique cuál es el tipo de variables que contiene el archivo, si la herramienta cargó correctamente los datos, la cantidad, formatos, valores etc.   Con su equipo haga una breve descripción del dataset cargado. Utilice los siguientes comandos para hacer la exploración\n\n#Relaciona la cantidad de registros y variables que contiene el dataset\ndata.shape\n\n(424, 18)\n\n\n\n#Lista todas las variables que contiene el dataset y especifica el tipo de dato\ndata.dtypes\n\nid                                         int64\nname                                      object\nhost_id                                    int64\nhost_name                                 object\nneighbourhood_group                      float64\nneighbourhood                             object\nlatitude                                 float64\nlongitude                                float64\nroom_type                                 object\nprice                                    float64\nminimum_nights                             int64\nnumber_of_reviews                          int64\nlast_review                       datetime64[ns]\nreviews_per_month                        float64\ncalculated_host_listings_count             int64\navailability_365                           int64\nnumber_of_reviews_ltm                      int64\nlicense                                  float64\ndtype: object\n\n\n\n#Exploración de variables continuas\n#Vamos a filtras las variables a analizar\n#Para el ejercicio complemente con las variables faltantes que puedan ser de interés.\n\ndata_continuas=data.loc[:, ['price','minimum_nights', 'availability_365']]\ndata_continuas.head()\n\n\n\n\n\n\n\n\nprice\nminimum_nights\navailability_365\n\n\n\n\n0\n882.0\n1\n330\n\n\n1\n106.0\n1\n86\n\n\n2\n99.0\n1\n341\n\n\n3\n58.0\n2\n248\n\n\n4\n50.0\n2\n340\n\n\n\n\n\n\n\n\n#Cómo se comporta la variable precio - analice el resultado\ndata_continuas['price'].describe()\n\ncount    374.000000\nmean     110.042781\nstd       86.746145\nmin       24.000000\n25%       68.000000\n50%       93.000000\n75%      122.750000\nmax      882.000000\nName: price, dtype: float64\n\n\n\n# Ahora vamos a generar las estadísticas descriptivas para todas las variables a la vez.\n# Analice el resultado\n\nvariables_continuas = ['price','minimum_nights', 'availability_365']\nestadisticas = data[variables_continuas].describe().T\n\n# Mostramos las estadísticas\nprint(\"Estadísticas descriptivas\")\nprint(estadisticas)\n\nEstadísticas descriptivas\n                  count        mean         std   min     25%    50%     75%  \\\nprice             374.0  110.042781   86.746145  24.0   68.00   93.0  122.75   \nminimum_nights    424.0    5.693396    9.627107   1.0    1.00    2.0    3.00   \navailability_365  424.0  233.261792  119.275432   0.0  119.75  268.0  341.25   \n\n                    max  \nprice             882.0  \nminimum_nights     70.0  \navailability_365  365.0  \n\n\n\ndata_continuas.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 424 entries, 0 to 423\nData columns (total 3 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   price             374 non-null    float64\n 1   minimum_nights    424 non-null    int64  \n 2   availability_365  424 non-null    int64  \ndtypes: float64(1), int64(2)\nmemory usage: 10.1 KB\n\n\n\n# Ahora vamos a analizar el comportamiento de manera gráfica para lo cual cargamos la librería\nimport matplotlib.pyplot as plt\n\n# Histogramas de frecuencia\ndata[variables_continuas].hist('price', figsize=(3, 3), bins=20)\nplt.tight_layout()\nplt.show()\n\n#Analiza el resultado y explora el código para mejorar el gráfico\n\n\n\n\n\n\n\n\n\n#Ahora probemos otra sintáxis\n\ndata[data['price'] &lt;= 200]['price'].hist(figsize=(3, 3), bins=10)\n\nplt.title('Histograma de price (&lt;= 200)')\nplt.xlabel('Price')\nplt.ylabel('Frecuencia')\nplt.tight_layout()\nplt.show()\n\n#Analiza el resultado y comparte tus conclusiones.\n#Compara las dos sintaxis, que observas?\n\n\n\n\n\n\n\n\n\ndata_continuas2=data.loc[:, ['price','neighbourhood']]\ndata_continuas2.head(10)\n\n\n\n\n\n\n\n\nprice\nneighbourhood\n\n\n\n\n0\n882.0\nFOURTEENTH WARD\n\n\n1\n106.0\nTHIRTEENTH WARD\n\n\n2\n99.0\nSIXTH WARD\n\n\n3\n58.0\nNINTH WARD\n\n\n4\n50.0\nNINTH WARD\n\n\n5\n93.0\nSIXTH WARD\n\n\n6\n156.0\nFOURTEENTH WARD\n\n\n7\n142.0\nFOURTEENTH WARD\n\n\n8\n96.0\nSIXTH WARD\n\n\n9\n88.0\nSIXTH WARD\n\n\n\n\n\n\n\n\n# Calculamos la frecuencia por cada valor que toma la variable\nfrecuencia_neighbourhood = data_continuas2['neighbourhood'].value_counts()\nprint(frecuencia_neighbourhood)\n\nneighbourhood\nSIXTH WARD         96\nSECOND WARD        51\nTENTH WARD         44\nTHIRTEENTH WARD    42\nTHIRD WARD         39\nNINTH WARD         32\nFOURTEENTH WARD    24\nFIFTEENTH WARD     18\nSEVENTH WARD       16\nELEVENTH WARD      15\nFOURTH WARD        14\nEIGHTH WARD        11\nFIRST WARD          9\nFIFTH WARD          7\nTWELFTH WARD        6\nName: count, dtype: int64\n\n\n\nplot_frec_abs = data_continuas2['neighbourhood'].value_counts().plot(kind='bar', title='Frecuencia de neighbourhood')\n\nplt.xlabel('neighbourhood')\nplt.ylabel('Frecuencia absoluta')\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Ahora vamos a realizar el análisis con los boxplot\ndata_continuas2.boxplot('price',by=\"neighbourhood\", figsize=(5,5))\nplt.xticks(rotation=90)\nplt.show()",
    "crumbs": [
      "Talleres",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Taller 1</span>"
    ]
  },
  {
    "objectID": "Taller_1/practica1_Ecopetrol.html#vamos-a-revisar-lo-que-hemos-aprendido-hasta-acá",
    "href": "Taller_1/practica1_Ecopetrol.html#vamos-a-revisar-lo-que-hemos-aprendido-hasta-acá",
    "title": "Sesión 1: Analítica descriptiva de datos",
    "section": "Vamos a revisar lo que hemos aprendido hasta acá",
    "text": "Vamos a revisar lo que hemos aprendido hasta acá\n\n¿Qué información nos proporcionan las estadísticas descriptivas?\n\n\n¿Qué información nos proporcionan los gráficos?\n\n\nCómo cientifico de datos cuál es tu recomendación del método a utilizar para analizar variables continuas?\n\n#Ahora vamos a explorar un tipo de gráfico que combina los dos métodos.\ndata[data['price']&lt;=100].boxplot('price')\n\nplt.title('Boxplot de Price (&lt;= 100)')\nplt.ylabel('Price')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nAhora vamos a analizar las variables categóricas\n\n#Seleccionamos en el dataset las variables categóricas de interés\nvariables_categoricas = ['neighbourhood','room_type']\n\n# Calculamos la frecuencia por cada valor que toma la variable\nfrecuencia_neighbourhood = data['room_type'].value_counts()\nprint(frecuencia_neighbourhood)\n\nroom_type\nEntire home/apt    308\nPrivate room       116\nName: count, dtype: int64\n\n\n\nplot_frec_abs = data['room_type'].value_counts().plot(kind='bar', title='Frecuencia de neighbourhood')\n\nplt.xlabel('room_type')\nplt.ylabel('Frecuencia absoluta')\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nReplique el ejercicio para la vaiable room_type\n\n#Esta sintaxis permite generar la tabla de frecuencias para las dos variables a la vez\n\nfor col in variables_categoricas:\n    print(f\"Frecuencia de valores en la variable '{col}':\")\n    print(data[col].value_counts())\n    print(\"\\n\" + \"-\"*40 + \"\\n\")\n\nFrecuencia de valores en la variable 'neighbourhood':\nneighbourhood\nSIXTH WARD         96\nSECOND WARD        51\nTENTH WARD         44\nTHIRTEENTH WARD    42\nTHIRD WARD         39\nNINTH WARD         32\nFOURTEENTH WARD    24\nFIFTEENTH WARD     18\nSEVENTH WARD       16\nELEVENTH WARD      15\nFOURTH WARD        14\nEIGHTH WARD        11\nFIRST WARD          9\nFIFTH WARD          7\nTWELFTH WARD        6\nName: count, dtype: int64\n\n----------------------------------------\n\nFrecuencia de valores en la variable 'room_type':\nroom_type\nEntire home/apt    308\nPrivate room       116\nName: count, dtype: int64\n\n----------------------------------------\n\n\n\n\n#Ahora descubre que pasa con esta sintaxis\nfrecuencia_neighbourhood = data[variables_categoricas].value_counts()\nprint(frecuencia_neighbourhood)\n\nneighbourhood    room_type      \nSIXTH WARD       Entire home/apt    83\nSECOND WARD      Entire home/apt    45\nTHIRD WARD       Entire home/apt    33\nTENTH WARD       Private room       25\nTHIRTEENTH WARD  Entire home/apt    23\nTENTH WARD       Entire home/apt    19\nTHIRTEENTH WARD  Private room       19\nNINTH WARD       Entire home/apt    17\n                 Private room       15\nSEVENTH WARD     Entire home/apt    15\nFOURTEENTH WARD  Entire home/apt    14\nFIFTEENTH WARD   Entire home/apt    14\nSIXTH WARD       Private room       13\nFOURTH WARD      Entire home/apt    12\nFOURTEENTH WARD  Private room       10\nELEVENTH WARD    Private room        9\nFIRST WARD       Entire home/apt     9\nEIGHTH WARD      Entire home/apt     8\nSECOND WARD      Private room        6\nTHIRD WARD       Private room        6\nELEVENTH WARD    Entire home/apt     6\nFIFTH WARD       Entire home/apt     5\nTWELFTH WARD     Entire home/apt     5\nFIFTEENTH WARD   Private room        4\nEIGHTH WARD      Private room        3\nFOURTH WARD      Private room        2\nFIFTH WARD       Private room        2\nSEVENTH WARD     Private room        1\nTWELFTH WARD     Private room        1\nName: count, dtype: int64\n\n\n\n#Mejoremos la visualización, pero antes filtremos el dataset para simplificar el código\n\ndata_categoricas=data.loc[:, ['neighbourhood','room_type']]\n\nTabla = pd.crosstab(index=data_categoricas.neighbourhood,columns=data_categoricas[\"room_type\"])\nTabla\n\n# Se obtuvo el mismo resultado?\n\n\n\n\n\n\n\nroom_type\nEntire home/apt\nPrivate room\n\n\nneighbourhood\n\n\n\n\n\n\nEIGHTH WARD\n8\n3\n\n\nELEVENTH WARD\n6\n9\n\n\nFIFTEENTH WARD\n14\n4\n\n\nFIFTH WARD\n5\n2\n\n\nFIRST WARD\n9\n0\n\n\nFOURTEENTH WARD\n14\n10\n\n\nFOURTH WARD\n12\n2\n\n\nNINTH WARD\n17\n15\n\n\nSECOND WARD\n45\n6\n\n\nSEVENTH WARD\n15\n1\n\n\nSIXTH WARD\n83\n13\n\n\nTENTH WARD\n19\n25\n\n\nTHIRD WARD\n33\n6\n\n\nTHIRTEENTH WARD\n23\n19\n\n\nTWELFTH WARD\n5\n1\n\n\n\n\n\n\n\n\n\n# Agrupamos por la variable 'v' y contamos ocurrencias\nconteo = data_categoricas['room_type'].value_counts()\n\n# Creamos el gráfico de torta\nconteo.plot.pie(autopct='%1.1f%%', startangle=90, figsize=(6, 6))\n\n# Opcional: agregar título\nplt.title('Distribución de la variable Room Type')\n\n# Eliminar el eje Y que se añade por defecto\nplt.ylabel('')\n\n# Mostrar el gráfico\nplt.show()",
    "crumbs": [
      "Sesiones",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Sesión 1: Analítica descriptiva de datos</span>"
    ]
  },
  {
    "objectID": "Taller_1/practica1_Ecopetrol.html#análisis-bivariado-variables-continuas-vs-variables-categóricas",
    "href": "Taller_1/practica1_Ecopetrol.html#análisis-bivariado-variables-continuas-vs-variables-categóricas",
    "title": "Sesión 1: Analítica descriptiva de datos",
    "section": "Análisis bivariado (Variables continuas vs Variables categóricas)",
    "text": "Análisis bivariado (Variables continuas vs Variables categóricas)\nAhora vamos a integrar los dos tipos de variables en el análisis\n\n#Exploración de variables continuas y categórica a través de análisi bivariados.\n#Vamos a filtras las variables a analizar\n\ndata_bivariado=data.loc[:, ['price','minimum_nights', 'availability_365', 'room_type', 'neighbourhood']]\ndata_bivariado.head()\n\n\n\n\n\n\n\n\nprice\nminimum_nights\navailability_365\nroom_type\nneighbourhood\n\n\n\n\n0\n882.0\n1\n330\nEntire home/apt\nFOURTEENTH WARD\n\n\n1\n106.0\n1\n86\nEntire home/apt\nTHIRTEENTH WARD\n\n\n2\n99.0\n1\n341\nEntire home/apt\nSIXTH WARD\n\n\n3\n58.0\n2\n248\nEntire home/apt\nNINTH WARD\n\n\n4\n50.0\n2\n340\nPrivate room\nNINTH WARD\n\n\n\n\n\n\n\n\n#El siguiente código nos permite responder a la pregunta de ¿Cuál es el precio promedio de alquiler por tipo de habitación?\n\ndata_bivariado.pivot_table(values='price',columns='room_type',aggfunc=\"mean\").round(2)\n\n\n\n\n\n\n\nroom_type\nEntire home/apt\nPrivate room\n\n\n\n\nprice\n125.02\n69.56\n\n\n\n\n\n\n\n\n#Ahora vamos a ajustar la sintaxis para obtener distintas métricas para la misma variable\n\ndata_bivariado.pivot_table(values='price',columns='room_type',aggfunc=[\"mean\", \"median\", \"std\"]).round(2)\n\n\n\n\n\n\n\n\nmean\nmedian\nstd\n\n\nroom_type\nEntire home/apt\nPrivate room\nEntire home/apt\nPrivate room\nEntire home/apt\nPrivate room\n\n\n\n\nprice\n125.02\n69.56\n101.0\n56.0\n94.17\n40.98\n\n\n\n\n\n\n\n\n# Mejoremos la visualización\n\ntabla=data_bivariado.pivot_table(values='price',columns='room_type',aggfunc=['mean', 'median', 'std']).round(2)\ntabla_final = tabla.stack(level=1, future_stack=True).reset_index()\nprint(tabla_final)\n\n  level_0        room_type    mean  median    std\n0   price  Entire home/apt  125.02   101.0  94.17\n1   price     Private room   69.56    56.0  40.98\n\n\n\n# Ahora vamos a incluir más variables continuas\ntabla_multi = data_bivariado.pivot_table(\n    values=['price', 'minimum_nights', 'availability_365'],\n    index=['room_type', 'neighbourhood'],\n    aggfunc=['mean', 'median', 'std']\n).round(2)\n\nprint(tabla_multi)\n\n                                            mean                         \\\n                                availability_365 minimum_nights   price   \nroom_type       neighbourhood                                             \nEntire home/apt EIGHTH WARD               226.25           5.25  195.25   \n                ELEVENTH WARD             242.33           1.83  114.20   \n                FIFTEENTH WARD            317.93           5.64  221.50   \n                FIFTH WARD                245.20           2.00  106.00   \n                FIRST WARD                173.44           5.78  134.86   \n                FOURTEENTH WARD           240.50           3.00  180.07   \n                FOURTH WARD               230.83           4.42  118.57   \n                NINTH WARD                257.29           7.71  151.80   \n                SECOND WARD               214.76           2.42  125.55   \n                SEVENTH WARD              213.13           6.07  104.00   \n                SIXTH WARD                234.64           4.39   97.86   \n                TENTH WARD                223.00           1.79  157.35   \n                THIRD WARD                262.94          11.48   87.38   \n                THIRTEENTH WARD           204.57           5.74  148.71   \n                TWELFTH WARD              163.00           7.60  107.00   \nPrivate room    EIGHTH WARD               169.00           1.00   62.33   \n                ELEVENTH WARD             309.56           6.67   43.57   \n                FIFTEENTH WARD            203.50           2.50   42.00   \n                FIFTH WARD                364.50           8.00   93.00   \n                FOURTEENTH WARD           142.00           4.10   60.80   \n                FOURTH WARD               178.50           2.00   87.00   \n                NINTH WARD                235.27           1.60   62.79   \n                SECOND WARD               187.00           1.17   89.80   \n                SEVENTH WARD              248.00           1.00   50.00   \n                SIXTH WARD                277.00           1.77  125.40   \n                TENTH WARD                248.60          16.16   68.95   \n                THIRD WARD                256.17          10.50   51.80   \n                THIRTEENTH WARD           209.84           9.95   63.00   \n                TWELFTH WARD              268.00           2.00   54.00   \n\n                                          median                        \\\n                                availability_365 minimum_nights  price   \nroom_type       neighbourhood                                            \nEntire home/apt EIGHTH WARD                200.0            3.0  207.0   \n                ELEVENTH WARD              262.5            2.0  104.0   \n                FIFTEENTH WARD             334.0            1.0  181.5   \n                FIFTH WARD                 357.0            2.0  106.5   \n                FIRST WARD                 163.0            2.0  114.0   \n                FOURTEENTH WARD            256.0            1.0  123.5   \n                FOURTH WARD                284.5            1.0  104.0   \n                NINTH WARD                 250.0            2.0  101.0   \n                SECOND WARD                279.0            1.0  108.0   \n                SEVENTH WARD               252.0            2.0  106.5   \n                SIXTH WARD                 291.0            2.0   93.0   \n                TENTH WARD                 318.0            1.0  118.0   \n                THIRD WARD                 268.0            4.0   89.5   \n                THIRTEENTH WARD            207.0            2.0  109.0   \n                TWELFTH WARD               200.0            3.0  119.5   \nPrivate room    EIGHTH WARD                140.0            1.0   53.0   \n                ELEVENTH WARD              324.0            2.0   44.0   \n                FIFTEENTH WARD             230.5            2.5   41.0   \n                FIFTH WARD                 364.5            8.0   93.0   \n                FOURTEENTH WARD            109.0            1.0   59.5   \n                FOURTH WARD                178.5            2.0   87.0   \n                NINTH WARD                 266.0            2.0   53.0   \n                SECOND WARD                184.0            1.0   58.0   \n                SEVENTH WARD               248.0            1.0   50.0   \n                SIXTH WARD                 334.0            1.0  127.0   \n                TENTH WARD                 300.0           18.0   56.0   \n                THIRD WARD                 361.0            1.5   37.0   \n                THIRTEENTH WARD            239.0            3.0   56.0   \n                TWELFTH WARD               268.0            2.0   54.0   \n\n                                             std                         \n                                availability_365 minimum_nights   price  \nroom_type       neighbourhood                                            \nEntire home/apt EIGHTH WARD               120.56           4.80   48.03  \n                ELEVENTH WARD             121.40           0.75   21.64  \n                FIFTEENTH WARD             64.16          10.36  142.56  \n                FIFTH WARD                157.52           0.71   12.99  \n                FIRST WARD                131.35           9.31   63.71  \n                FOURTEENTH WARD            92.00           3.62  210.39  \n                FOURTH WARD               113.02           8.76   27.99  \n                NINTH WARD                 95.90          17.48  183.49  \n                SECOND WARD               129.41           3.47   65.36  \n                SEVENTH WARD              145.84           9.59   42.72  \n                SIXTH WARD                126.84           7.73   27.44  \n                TENTH WARD                140.31           1.44  109.35  \n                THIRD WARD                 90.84          12.33   18.06  \n                THIRTEENTH WARD           115.37          12.70  149.22  \n                TWELFTH WARD              112.21          11.41   32.09  \nPrivate room    EIGHTH WARD               182.24           0.00   16.17  \n                ELEVENTH WARD              51.03           7.81    9.07  \n                FIFTEENTH WARD            171.93           0.58    4.58  \n                FIFTH WARD                  0.71           9.90     NaN  \n                FOURTEENTH WARD            86.55           8.43    8.00  \n                FOURTH WARD                 0.71           1.41   24.04  \n                NINTH WARD                103.18           0.51   31.89  \n                SECOND WARD               146.21           0.41   63.58  \n                SEVENTH WARD                 NaN            NaN     NaN  \n                SIXTH WARD                113.72           1.54   66.57  \n                TENTH WARD                119.71          12.90   42.37  \n                THIRD WARD                166.69          14.35   24.36  \n                THIRTEENTH WARD           107.85          12.20   25.54  \n                TWELFTH WARD                 NaN            NaN     NaN  \n\n\n\n# Ahora vamos a realizar el análisis con los boxplot\ndata_bivariado.boxplot('price',by=\"room_type\", figsize=(5,5))\n\n\n\n\n\n\n\n\n\ndf_private_room= data[data['room_type'] == 'Private room']\ndf_private_room.head(5)\n\n\n\n\n\n\n\n\nid\nname\nhost_id\nhost_name\nneighbourhood_group\nneighbourhood\nlatitude\nlongitude\nroom_type\nprice\nminimum_nights\nnumber_of_reviews\nlast_review\nreviews_per_month\ncalculated_host_listings_count\navailability_365\nnumber_of_reviews_ltm\nlicense\n\n\n\n\n4\n24606880\nThe Western Suite\n98744672\nBela\nNaN\nNINTH WARD\n42.65431\n-73.78178\nPrivate room\n50.0\n2\n48\n2025-02-27\n0.62\n8\n340\n9\nNaN\n\n\n11\n937927979762952960\nHudson 4 at The Argus Hotel\n526358730\nArgus\nNaN\nTENTH WARD\n42.66043\n-73.77432\nPrivate room\n165.0\n1\n2\n2024-10-12\n0.33\n12\n300\n2\nNaN\n\n\n12\n937837897631191808\nHudson 2 at The Argus Hotel\n526358730\nArgus\nNaN\nSIXTH WARD\n42.65867\n-73.77479\nPrivate room\n165.0\n1\n2\n2023-12-31\n0.11\n12\n304\n0\nNaN\n\n\n15\n938271786418327552\nKnickerbocker 3 The Argus Hotel\n526358730\nArgus\nNaN\nSIXTH WARD\n42.65868\n-73.77333\nPrivate room\n243.0\n1\n0\nNaT\nNaN\n12\n340\n0\nNaN\n\n\n16\n937935210290408960\nHudson 5 at The Argus Hotel\n526358730\nArgus\nNaN\nSIXTH WARD\n42.65847\n-73.77272\nPrivate room\n161.0\n1\n5\n2024-12-29\n0.30\n12\n336\n4\nNaN",
    "crumbs": [
      "Sesiones",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Sesión 1: Analítica descriptiva de datos</span>"
    ]
  },
  {
    "objectID": "Taller_1/practica1_Ecopetrol.html#bonus-track",
    "href": "Taller_1/practica1_Ecopetrol.html#bonus-track",
    "title": "Sesión 1: Analítica descriptiva de datos",
    "section": "Bonus track",
    "text": "Bonus track\n\nMétricas disponibles en numpy para variables continuas\n\n\n📊 Estadísticas básicas\n\n\n\n\n\n\n\n\nMétrica\nDescripción\nEjemplo en aggfunc\n\n\n\n\nnp.mean\nMedia (promedio)\naggfunc=np.mean\n\n\nnp.sum\nSuma total\naggfunc=np.sum\n\n\nnp.min\nValor mínimo\naggfunc=np.min\n\n\nnp.max\nValor máximo\naggfunc=np.max\n\n\nnp.median\nMediana\naggfunc=np.median\n\n\nnp.std\nDesviación estándar\naggfunc=np.std\n\n\nnp.var\nVarianza\naggfunc=np.var       |",
    "crumbs": [
      "Sesiones",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Sesión 1: Analítica descriptiva de datos</span>"
    ]
  },
  {
    "objectID": "Taller_1/practica1_Ecopetrol.html#sesión-1-analítica-descriptiva-de-datos",
    "href": "Taller_1/practica1_Ecopetrol.html#sesión-1-analítica-descriptiva-de-datos",
    "title": "Taller 1",
    "section": "Sesión 1 : Analítica descriptiva de datos",
    "text": "Sesión 1 : Analítica descriptiva de datos",
    "crumbs": [
      "Talleres",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Taller 1</span>"
    ]
  },
  {
    "objectID": "Taller_2/practica2_Ecopetrol_v1.html",
    "href": "Taller_2/practica2_Ecopetrol_v1.html",
    "title": "Sesión 2: Transformación y aseguramiento de calidad",
    "section": "",
    "text": "Preparación del ambiente de trabajo\nEsta práctica se realizará sobre los datos obtenidos de la página https://www.kaggle.com  Antes de iniciar acceda al archivo ReadMe.txt disponible en la carpeta y revise la descripción de los datos a trabajar en la sesión.",
    "crumbs": [
      "Sesiones",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sesión 2: Transformación  y aseguramiento de calidad</span>"
    ]
  },
  {
    "objectID": "Taller_2/practica2_Ecopetrol_v1.html#sesión-2-transformación-y-aseguramiento-de-calidad",
    "href": "Taller_2/practica2_Ecopetrol_v1.html#sesión-2-transformación-y-aseguramiento-de-calidad",
    "title": "Taller 2",
    "section": "Sesión 2: Transformación y aseguramiento de calidad",
    "text": "Sesión 2: Transformación y aseguramiento de calidad",
    "crumbs": [
      "Talleres",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Taller 2</span>"
    ]
  },
  {
    "objectID": "Taller_2/practica2_Ecopetrol_v1.html#ecopetrol---universidad-de-los-andes",
    "href": "Taller_2/practica2_Ecopetrol_v1.html#ecopetrol---universidad-de-los-andes",
    "title": "Taller 2",
    "section": "Ecopetrol - Universidad de los Andes",
    "text": "Ecopetrol - Universidad de los Andes\nEsta práctica se realizará sobre los datos obtenidos de la página https://www.kaggle.com  Antes de iniciar acceda al archivo ReadMe.txt disponible en la carpeta y revise la descripción de los datos a trabajar en la sesión.\n\nPreparación del ambiente de trabajo\n\nCargue de librerías\n\nimport os, sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n\n\nLectura de los datos\n Ingrese a la carpeta compartida en Onedrive TALLER 2 y descargue los 3 archivos disponibles, tenga en cuenta que están en formato distinto  Configuración del directorio\n\n%cd C:\\Users\\X1 Carbon\\OneDrive\\Documentos\\1_NEICON\\1_Proyectos\\2_Carpeta Tito\\Capacitación UniAndes_Ecopetrol\\Datsets\\Taller_2\\Modificados\n\n\n# Cague de los archivos en formato texto o excel\ndf_PdM_telemetry=pd.read_csv('PdM_telemetry.csv', sep=';')\ndf_PdM_telemetry.head(4)\n\n\ndf_PdM_errors=pd.read_excel('PdM_errors.xlsx')\ndf_PdM_errors.head(4)\n\n\n\nExploración de los datos\n Utilice los comandos aprendidos en la sesión 1 para explorar los datos disponibles en los dataset PdM_telemetry y PdM_errors  Analice la cantidad de registros, cantidad y tipo de variables\n\n# Vamos a cargar el archivo con todas las hojas disponibles en el archivo, creando un diccionario\narchivo_excel = pd.read_excel('Dataset_integrado.xlsx', sheet_name=None)\n\n# Revisamos los nombres de las hojas\nprint(\"Hojas disponibles:\", archivo_excel.keys())\n\n\n# Para visualizar el contenido de cada hoja usamos esta instrucción\nfor nombre_hoja, df in archivo_excel.items():\n    print(f\"\\nMostrando las primeras filas de la hoja: {nombre_hoja}\")\n    print(df.head())\n\n\n## Comando Para crear un dataframe con el contenido de cada hoja\n#df_hoja1 = archivo_excel['Hoja1']  # reemplaza 'Hoja1' por el nombre real\n\n#Acá el ejemplo para los datos de PdM_failures, replica el ejercicio para todas y realiza una exploración rápida del contenido empleando \n#lo aprendido en la sesion anterior\n\ndf_PdM_maint = archivo_excel['PdM_maint']\n\ndf_PdM_failures = archivo_excel['PdM_failures']\n\ndf_PdM_machines = archivo_excel['PdM_machines']\n\n\ndf_PdM_failures.shape\n\n\ndf_PdM_failures.dtypes\n\n\n\nQuiz:\n\n1. ¿Cuántos dataset hay en total?\n\n\n2. ¿Qué cantidad de registro tiene cada dataset?\n\ndf_PdM_failures n =\n\n\ndf_PdM_errors n =\n\n\ndf_PdM_maint n =\n\n\ndf_PdM_PdM_machines n =\n\n\ndf_PdM_telemetry n =\n\n\n\n3. ¿Qué cantidad de variables tiene cada dataset?\n\ndf_PdM_failures:\n\n\ndf_PdM_errors:\n\n\ndf_PdM_maint:\n\n\ndf_PdM_PdM_machines:\n\n\ndf_PdM_telemetry:\n\n\n\n4. ¿Qué tipo de datos contiene cada dataset?\n\ndf_PdM_failures:\n\n\ndf_PdM_errors:\n\n\ndf_PdM_maint:\n\n\ndf_PdM_PdM_machines:\n\n\ndf_PdM_telemetry:",
    "crumbs": [
      "Talleres",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Taller 2</span>"
    ]
  },
  {
    "objectID": "Taller_2/practica2_Ecopetrol_v1.html#evaluación-de-calidad-de-los-datos",
    "href": "Taller_2/practica2_Ecopetrol_v1.html#evaluación-de-calidad-de-los-datos",
    "title": "Sesión 2: Transformación y aseguramiento de calidad",
    "section": "Evaluación de calidad de los datos",
    "text": "Evaluación de calidad de los datos\n\n#Para la exploración de variables vamos a utilizar una nueva librería.  Si esta no está disponible, la puede instalar en el \n#promt de Anaconda con la siguiente instrucción.  pip install ydata-profiling\n# Para facilitar el ejercicio listamos los dataframe que hemos cargado, así podrá copiar y pegar el nombre en las dos líneas de la siguiente sintáxis:\n# df_PdM_machines, df_PdM_failures, df_PdM_c, df_PdM_errors, df_PdM_telemetry\n\nfrom ydata_profiling import ProfileReport\n\nprofile = ProfileReport(df_PdM_telemetry)  #Esta sintaxis genera el reporte\nprofile.to_file(\"Reporte_PdM_telemetry\") #Esta sintaxis guarda el reporte en un archivo HTML **Recomendado**\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[20], line 6\n      1 #Para la exploración de variables vamos a utilizar una nueva librería.  Si esta no está disponible, la puede instalar en el \n      2 #promt de Anaconda con la siguiente instrucción.  pip install ydata-profiling\n      3 # Para facilitar el ejercicio listamos los dataframe que hemos cargado, así podrá copiar y pegar el nombre en las dos líneas de la siguiente sintáxis:\n      4 # df_PdM_machines, df_PdM_failures, df_PdM_c, df_PdM_errors, df_PdM_telemetry\n----&gt; 6 from ydata_profiling import ProfileReport\n      8 profile = ProfileReport(df_PdM_telemetry)  #Esta sintaxis genera el reporte\n      9 profile.to_file(\"Reporte_PdM_telemetry\") #Esta sintaxis guarda el reporte en un archivo HTML **Recomendado**\n\nModuleNotFoundError: No module named 'ydata_profiling'\n\n\n\nRealice un breve informe de los resultados de la evaluación de calidad. ¿hay ajustes que realizar a los datos?",
    "crumbs": [
      "Sesiones",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sesión 2: Transformación  y aseguramiento de calidad</span>"
    ]
  },
  {
    "objectID": "Taller_2/practica2_Ecopetrol_v1.html#mejoramiento-de-calidad-de-los-datos",
    "href": "Taller_2/practica2_Ecopetrol_v1.html#mejoramiento-de-calidad-de-los-datos",
    "title": "Sesión 2: Transformación y aseguramiento de calidad",
    "section": "Mejoramiento de calidad de los datos",
    "text": "Mejoramiento de calidad de los datos\n\nEliminación de duplicados\n\ndf_PdM_telemetry.shape\n\n(876120, 7)\n\n\n\n# Elimina duplicados para el dataframe df_PdM_telemetry\ntelemetry_sin_duplicados = df_PdM_telemetry.drop_duplicates() \ntelemetry_sin_duplicados.shape\n\n(876100, 7)\n\n\n\n\nCorrección de valores extremos - Categorización\n\n### Crea 5 grupos de igual amplitud sobre los valores de la variable volt del dataset telemetry_sin_duplicados\n### Almacena el resultado en la variable GRUPO_Volt\n    \n# Creamos una copia del dataframe original\ntelemetry_sin_duplicados = telemetry_sin_duplicados.copy()\n\ntelemetry_sin_duplicados.loc[:, 'GRUPO_Volt'] = pd.cut(\n    telemetry_sin_duplicados['volt'],\n    bins=5,  # número de categorías deseadas\n    labels=['GRUPO1', 'GRUPO2', 'GRUPO3', 'GRUPO4', 'GRUPO5'],\n    include_lowest=True\n)\n\ntelemetry_sin_duplicados.head()\n\n\n\n\n\n\n\n\ndatetime\nmachineID\nvolt\nrotate\npressure\nvibration\nColumna1\nGRUPO_Volt\n\n\n\n\n0\n8/12/2015 15:00\n79\n194.071741\n484.698993\n101.085953\n47.317101\nNaN\nGRUPO2\n\n\n1\n11/12/2015 06:00\n15\n153.546984\n454.170621\n113.613686\n38.416344\nNaN\nGRUPO1\n\n\n2\n28/6/2015 20:00\n62\n122.492361\n386.409669\n102.970808\n41.206891\nNaN\nGRUPO1\n\n\n3\n24/7/2015 04:00\n51\n183.098835\n448.021654\n108.709299\n41.493329\nNaN\nGRUPO2\n\n\n4\n28/1/2015 15:00\n60\n167.079133\n404.744703\n104.446543\n35.706153\nNaN\nGRUPO2\n\n\n\n\n\n\n\n\n# Vamos a validar si el valor extremo queda en el grupo 5\n\n# Filtramos el dataframe\nfiltro_G5 = telemetry_sin_duplicados[telemetry_sin_duplicados['GRUPO_Volt'] == 'GRUPO5']\n\n# Ordenamos el dataframe de manera descendente\ndata_ordenado = filtro_G5.sort_values(by='volt', ascending=False)\ndata_ordenado.head(7)\n\n\n\n\n\n\n\n\ndatetime\nmachineID\nvolt\nrotate\npressure\nvibration\nColumna1\nGRUPO_Volt\n\n\n\n\n93107\n21/9/2015 14:00\n39\n382.687076\n481.239810\nNaN\n46.432730\nNaN\nGRUPO5\n\n\n717516\n15/12/2015 08:00\n64\n382.687076\n371.393288\nNaN\n37.055618\nNaN\nGRUPO5\n\n\n742953\n14/12/2015 20:00\n61\n382.687076\n405.128743\nNaN\n40.031070\nNaN\nGRUPO5\n\n\n759631\n17/1/2015 11:00\n13\n382.687076\n520.070835\nNaN\n38.855552\nNaN\nGRUPO5\n\n\n780556\n8/5/2015 07:00\n25\n382.687076\n384.628061\nNaN\n52.098697\nNaN\nGRUPO5\n\n\n\n\n\n\n\n\n# Contamos cuantos registros quedaron en cada Grupo\nfrecuencia_Grupos = telemetry_sin_duplicados['GRUPO_Volt'].value_counts()\nprint(frecuencia_Grupos)\n\nGRUPO_Volt\nGRUPO2    744544\nGRUPO1    126347\nGRUPO3      5204\nGRUPO5         5\nGRUPO4         0\nName: count, dtype: int64\n\n\n\n# Sintaxis para crear 5 grupos con cortes pesonalizados\n\ndef categorizar(x):\n    if x &lt;= 155:\n        return 'GRUPO1'\n    elif x &lt;= 168:\n        return 'GRUPO2'\n    elif x &lt;= 195:\n        return 'GRUPO3'\n    else:\n        return 'GRUPO4'\n\ntelemetry_sin_duplicados.loc[:, 'GRUPO_Volt_2'] = telemetry_sin_duplicados['volt'].apply(categorizar)\ntelemetry_sin_duplicados.head()\n\n\n\n\n\n\n\n\ndatetime\nmachineID\nvolt\nrotate\npressure\nvibration\nColumna1\nGRUPO_Volt\nGRUPO_Volt_2\n\n\n\n\n0\n8/12/2015 15:00\n79\n194.071741\n484.698993\n101.085953\n47.317101\nNaN\nGRUPO2\nGRUPO3\n\n\n1\n11/12/2015 06:00\n15\n153.546984\n454.170621\n113.613686\n38.416344\nNaN\nGRUPO1\nGRUPO1\n\n\n2\n28/6/2015 20:00\n62\n122.492361\n386.409669\n102.970808\n41.206891\nNaN\nGRUPO1\nGRUPO1\n\n\n3\n24/7/2015 04:00\n51\n183.098835\n448.021654\n108.709299\n41.493329\nNaN\nGRUPO2\nGRUPO3\n\n\n4\n28/1/2015 15:00\n60\n167.079133\n404.744703\n104.446543\n35.706153\nNaN\nGRUPO2\nGRUPO2\n\n\n\n\n\n\n\n\n# Contamos cuantos registros quedaron en cada Grupo y comparamos si hubo cambios según la forma de agrupar\nTabla = pd.crosstab(\n    index=telemetry_sin_duplicados['GRUPO_Volt'],\n    columns=telemetry_sin_duplicados['GRUPO_Volt_2'],\n    margins=True,                # Agrega totales\n    margins_name='Total'        # Nombre de la fila/columna de totales\n)\n\nTabla\n\n\n\n\n\n\n\nGRUPO_Volt_2\nGRUPO1\nGRUPO2\nGRUPO3\nGRUPO4\nTotal\n\n\nGRUPO_Volt\n\n\n\n\n\n\n\n\n\nGRUPO1\n126347\n0\n0\n0\n126347\n\n\nGRUPO2\n7975\n244354\n444358\n47857\n744544\n\n\nGRUPO3\n0\n0\n0\n5204\n5204\n\n\nGRUPO5\n0\n0\n0\n5\n5\n\n\nTotal\n134322\n244354\n444358\n53066\n876100\n\n\n\n\n\n\n\n\n# Porcentaje sobre el total general\ntabla_porcentaje_total = Tabla / Tabla.loc['Total', 'Total']*100\ntabla_porcentaje_total = tabla_porcentaje_total.map(lambda x: f\"{x:.2f}%\")\ntabla_porcentaje_total\n\n\n\n\n\n\n\nGRUPO_Volt_2\nGRUPO1\nGRUPO2\nGRUPO3\nGRUPO4\nTotal\n\n\nGRUPO_Volt\n\n\n\n\n\n\n\n\n\nGRUPO1\n14.42%\n0.00%\n0.00%\n0.00%\n14.42%\n\n\nGRUPO2\n0.91%\n27.89%\n50.72%\n5.46%\n84.98%\n\n\nGRUPO3\n0.00%\n0.00%\n0.00%\n0.59%\n0.59%\n\n\nGRUPO5\n0.00%\n0.00%\n0.00%\n0.00%\n0.00%\n\n\nTotal\n15.33%\n27.89%\n50.72%\n6.06%\n100.00%\n\n\n\n\n\n\n\n\n# segmentar por cuantiles y asignar etiquetas a cada Grupo \ntelemetry_sin_duplicados['volt_grupo'] = pd.qcut(telemetry_sin_duplicados['volt'], q=4, labels=['Bajo', 'Medio-Bajo', 'Medio-Alto', 'Alto'])\n\n# Verifica el resultado\nprint(telemetry_sin_duplicados[['volt', 'volt_grupo']].head(10))\n\n         volt  volt_grupo\n0  194.071741        Alto\n1  153.546984        Bajo\n2  122.492361        Bajo\n3  183.098835        Alto\n4  167.079133  Medio-Bajo\n5  147.973627        Bajo\n6  153.472810        Bajo\n7  186.109859        Alto\n8  216.477793        Alto\n9  167.311133  Medio-Bajo\n\n\n\nfrecuencia_Grupos = telemetry_sin_duplicados['volt_grupo'].value_counts()\nprint(frecuencia_Grupos)\n\nvolt_grupo\nBajo          219025\nMedio-Bajo    219025\nMedio-Alto    219025\nAlto          219025\nName: count, dtype: int64\n\n\n\n# segmentar por deciles\ntelemetry_sin_duplicados['volt_grupo'] = pd.qcut(telemetry_sin_duplicados['volt'], q=10)\n\n# Verifica el resultado\nprint(telemetry_sin_duplicados[['volt', 'volt_grupo']].head(10))\n\n         volt          volt_grupo\n0  194.071741  (190.617, 382.687]\n1  153.546984  (151.081, 157.729]\n2  122.492361   (97.333, 151.081]\n3  183.098835  (178.679, 183.615]\n4  167.079133   (166.74, 170.607]\n5  147.973627   (97.333, 151.081]\n6  153.472810  (151.081, 157.729]\n7  186.109859  (183.615, 190.617]\n8  216.477793  (190.617, 382.687]\n9  167.311133   (166.74, 170.607]\n\n\n\n\nCreacion de un nuevo dataset - Extracción\n\nplt.boxplot(x=telemetry_sin_duplicados['volt']);\n\n\n\n\n\n\n\n\n\nseventy_fifth = telemetry_sin_duplicados['volt'].quantile(0.75)\ntwenty_fifth = telemetry_sin_duplicados['volt'].quantile(0.25)\nvolt_iqr = seventy_fifth - twenty_fifth\nprint(volt_iqr)\n\n20.699494724999994\n\n\n\nupper = seventy_fifth + (1.5 * volt_iqr)\nlower = twenty_fifth - (1.5 * volt_iqr)\nprint(upper, lower)\n\n212.0536642125 129.25568531250002\n\n\n\n# Filtramos el dataframe\natipicos = telemetry_sin_duplicados[telemetry_sin_duplicados['volt'] &gt; 200]\natipicos.shape\n\n(28176, 10)\n\n\n\n\nReemplazar valores extremos en el dataframe (Imputación)\n\n# Calculamos las estadisticas descriptivas de Volt\ntelemetry_sin_duplicados['volt'].describe()\n\ncount    876100.000000\nmean        170.778872\nstd          15.517321\nmin          97.333604\n25%         160.304927\n50%         170.607338\n75%         181.004501\nmax         382.687076\nName: volt, dtype: float64\n\n\n\n# Reemplazamos en el dataframe sin duplicados, el valor atípico 382.687076, por 170.7788\ntelemetry_sin_duplicados.loc[telemetry_sin_duplicados['volt'] &gt; 300, 'volt'] = 170.7788\ntelemetry_sin_duplicados['volt'].describe()\n\ncount    876100.000000\nmean        170.777663\nstd          15.509061\nmin          97.333604\n25%         160.304927\n50%         170.607338\n75%         181.004422\nmax         255.124717\nName: volt, dtype: float64\n\n\n\n\nEl último recursos… eliminación\n\ntelemetry_sin_atipicos = telemetry_sin_duplicados[telemetry_sin_duplicados['volt'] != 382.687076]\ntelemetry_sin_atipicos.shape\n\n(876100, 10)",
    "crumbs": [
      "Sesiones",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sesión 2: Transformación  y aseguramiento de calidad</span>"
    ]
  },
  {
    "objectID": "Taller_2/practica2_Ecopetrol_v1.html#alternativas-para-resolver-el-caso-de-valores-faltantes",
    "href": "Taller_2/practica2_Ecopetrol_v1.html#alternativas-para-resolver-el-caso-de-valores-faltantes",
    "title": "Sesión 2: Transformación y aseguramiento de calidad",
    "section": "Alternativas para resolver el caso de valores faltantes",
    "text": "Alternativas para resolver el caso de valores faltantes\n\nMétodos de imputación\n\n# Analizamos aquellos registros donde faltan datos\n## Filtrar registros donde pressure es nulo \nfiltro_PressureNA = telemetry_sin_duplicados[telemetry_sin_duplicados['pressure'].isna()]\nfiltro_PressureNA.head(5)\n\n\n\n\n\n\n\n\ndatetime\nmachineID\nvolt\nrotate\npressure\nvibration\nColumna1\nGRUPO_Volt\nGRUPO_Volt_2\nvolt_grupo\n\n\n\n\n5153\n21/8/2015 20:00\n74\n170.918892\n430.724320\nNaN\n40.253415\nNaN\nGRUPO2\nGRUPO3\n(170.607, 174.508]\n\n\n30176\n23/4/2015 02:00\n1\n204.789754\n369.026200\nNaN\n39.667222\nNaN\nGRUPO2\nGRUPO4\n(190.617, 382.687]\n\n\n34217\n5/7/2015 18:00\n99\n174.221316\n427.978309\nNaN\n35.623057\nNaN\nGRUPO2\nGRUPO3\n(170.607, 174.508]\n\n\n39579\n5/6/2015 19:00\n83\n171.998008\n355.537555\nNaN\n30.515283\nNaN\nGRUPO2\nGRUPO3\n(170.607, 174.508]\n\n\n62420\n18/11/2015 13:00\n55\n167.379093\n408.034747\nNaN\n39.499060\nNaN\nGRUPO2\nGRUPO2\n(166.74, 170.607]\n\n\n\n\n\n\n\n\ntelemetry_sin_duplicados.isna().sum()\n\ndatetime             0\nmachineID            0\nvolt                 0\nrotate               0\npressure           100\nvibration            0\nColumna1        876100\nGRUPO_Volt           0\nGRUPO_Volt_2         0\nvolt_grupo           0\ndtype: int64\n\n\n\ntelemetry_sin_duplicados['pressure'].describe()\n\ncount    876000.000000\nmean        100.858828\nstd          11.048863\nmin          51.237106\n25%          93.498085\n50%         100.425947\n75%         107.555402\nmax         185.951998\nName: pressure, dtype: float64\n\n\n\ndf=telemetry_sin_duplicados.copy()\ndf['pressure'] = df['pressure'].fillna(df['pressure'].mean())           # imputación con media\ndf.isna().sum()\n\ndatetime             0\nmachineID            0\nvolt                 0\nrotate               0\npressure             0\nvibration            0\nColumna1        876100\nGRUPO_Volt           0\nGRUPO_Volt_2         0\nvolt_grupo           0\ndtype: int64\n\n\n\ndf=telemetry_sin_duplicados.copy()\ndf['pressure'] = df['pressure'].fillna(df['pressure'].median())         # imputación con mediana\ndf.isna().sum()\n\ndatetime             0\nmachineID            0\nvolt                 0\nrotate               0\npressure             0\nvibration            0\nColumna1        876100\nGRUPO_Volt           0\nGRUPO_Volt_2         0\nvolt_grupo           0\ndtype: int64\n\n\n\ndf=telemetry_sin_duplicados.copy()\ndf['pressure'] = df['pressure'].ffill()            # imputación forward / backward \ndf.isna().sum()\n# El método por method='ffill' usa el último valor conocido\n# El método por method='bfill' usa el siguiente valor conocido\n\ndatetime             0\nmachineID            0\nvolt                 0\nrotate               0\npressure             0\nvibration            0\nColumna1        876100\nGRUPO_Volt           0\nGRUPO_Volt_2         0\nvolt_grupo           0\ndtype: int64\n\n\n\ndf=telemetry_sin_duplicados.copy()\ndf['pressure'] = df['pressure'].interpolate(method='linear')       # imputación por interpolación lineal\ndf.isna().sum()\n\ndatetime             0\nmachineID            0\nvolt                 0\nrotate               0\npressure             0\nvibration            0\nColumna1        876100\nGRUPO_Volt           0\nGRUPO_Volt_2         0\nvolt_grupo           0\ndtype: int64",
    "crumbs": [
      "Sesiones",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sesión 2: Transformación  y aseguramiento de calidad</span>"
    ]
  },
  {
    "objectID": "Taller_2/practica2_Ecopetrol_v1.html#identificando-patrones-entre-las-variables",
    "href": "Taller_2/practica2_Ecopetrol_v1.html#identificando-patrones-entre-las-variables",
    "title": "Sesión 2: Transformación y aseguramiento de calidad",
    "section": "Identificando patrones entre las variables",
    "text": "Identificando patrones entre las variables\n\n#Analicemos los promedio de pressure por tipo de modelo de máquina, pero antes hay que integrar los datos de telemetría depurados y los datos de máquina\ndata_integrada = pd.merge(telemetry_sin_duplicados, df_PdM_machines, on='machineID', how='left')  \ndata_integrada.head()\n\n\n\n\n\n\n\n\ndatetime\nmachineID\nvolt\nrotate\npressure\nvibration\nColumna1\nGRUPO_Volt\nGRUPO_Volt_2\nvolt_grupo\nmodel\nage\n\n\n\n\n0\n8/12/2015 15:00\n79\n194.071741\n484.698993\n101.085953\n47.317101\nNaN\nGRUPO2\nGRUPO3\n(190.617, 382.687]\nmodel3\n14\n\n\n1\n11/12/2015 06:00\n15\n153.546984\n454.170621\n113.613686\n38.416344\nNaN\nGRUPO1\nGRUPO1\n(151.081, 157.729]\nmodel3\n14\n\n\n2\n28/6/2015 20:00\n62\n122.492361\n386.409669\n102.970808\n41.206891\nNaN\nGRUPO1\nGRUPO1\n(97.333, 151.081]\nmodel4\n20\n\n\n3\n24/7/2015 04:00\n51\n183.098835\n448.021654\n108.709299\n41.493329\nNaN\nGRUPO2\nGRUPO3\n(178.679, 183.615]\nmodel4\n19\n\n\n4\n28/1/2015 15:00\n60\n167.079133\n404.744703\n104.446543\n35.706153\nNaN\nGRUPO2\nGRUPO2\n(166.74, 170.607]\nmodel4\n3\n\n\n\n\n\n\n\n\n#Analicemos los promedio de pressure por tipo de modelo de máquina\ndata_integrada.pivot_table(values='pressure',columns='model',aggfunc=['median', 'mean', 'std']).round(2)\n\n\n\n\n\n\n\n\nmedian\nmean\nstd\n\n\nmodel\nmodel1\nmodel2\nmodel3\nmodel4\nmodel1\nmodel2\nmodel3\nmodel4\nmodel1\nmodel2\nmodel3\nmodel4\n\n\n\n\npressure\n100.67\n100.64\n100.32\n100.32\n101.27\n101.22\n100.67\n100.67\n11.47\n11.38\n10.85\n10.86\n\n\n\n\n\n\n\n\n# Se crea un arreglo con los valores que vamos a imputar\nvalores_por_categoria = {\n    'model1': 101.27,\n    'model2': 101.22,\n    'model3': 100.67,\n    'model4': 100.67\n}\n\ndata_integrada['pressure'] = data_integrada['pressure'].fillna(data_integrada['model'].map(valores_por_categoria))\n\n\n#Validamos si quedaron valores faltantes\ndata_integrada.isna().sum()\n\ndatetime             0\nmachineID            0\nvolt                 0\nrotate               0\npressure             0\nvibration            0\nColumna1        876100\nGRUPO_Volt           0\nGRUPO_Volt_2         0\nvolt_grupo           0\nmodel                0\nage                  0\ndtype: int64\n\n\n\n#### Agrupar registros bajo las categorías de v2,  sumando los valores de v1 \ndata_integrada = data_integrada.groupby('model', as_index=False)['pressure'].mean()\ndata_integrada\n\n# Otras métricas que podemos usar:\n# sum() - suma\n# mean() - Promedio\n# count() - Conteo de registro\n# min() - Valor(es) mínimo\n# max() - Valor(es) máximo\n# std() - Desviación estándar\n# var() - Varianza\n# nunique() - Conteo de valores únicos\n\n\n\n\n\n\n\n\nmodel\npressure\n\n\n\n\n0\nmodel1\n101.269020\n\n\n1\nmodel2\n101.216593\n\n\n2\nmodel3\n100.667934\n\n\n3\nmodel4\n100.672473\n\n\n\n\n\n\n\n\n# Eliminamos la variable Columna1 que tiene todos los datos faltantes\ndata_integrada.drop(columns=['Columna1'], inplace=True)\ndata_integrada.dtypes\n\n\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nCell In[67], line 2\n      1 # Eliminamos la variable Columna1 que tiene todos los datos faltantes\n----&gt; 2 data_integrada.drop(columns=['Columna1'], inplace=True)\n      3 data_integrada.dtypes\n\nFile ~/Documents/curso_data_analytics_andes/entorno_analitica_datos/lib/python3.13/site-packages/pandas/core/frame.py:5588, in DataFrame.drop(self, labels, axis, index, columns, level, inplace, errors)\n   5440 def drop(\n   5441     self,\n   5442     labels: IndexLabel | None = None,\n   (...)   5449     errors: IgnoreRaise = \"raise\",\n   5450 ) -&gt; DataFrame | None:\n   5451     \"\"\"\n   5452     Drop specified labels from rows or columns.\n   5453 \n   (...)   5586             weight  1.0     0.8\n   5587     \"\"\"\n-&gt; 5588     return super().drop(\n   5589         labels=labels,\n   5590         axis=axis,\n   5591         index=index,\n   5592         columns=columns,\n   5593         level=level,\n   5594         inplace=inplace,\n   5595         errors=errors,\n   5596     )\n\nFile ~/Documents/curso_data_analytics_andes/entorno_analitica_datos/lib/python3.13/site-packages/pandas/core/generic.py:4807, in NDFrame.drop(self, labels, axis, index, columns, level, inplace, errors)\n   4805 for axis, labels in axes.items():\n   4806     if labels is not None:\n-&gt; 4807         obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n   4809 if inplace:\n   4810     self._update_inplace(obj)\n\nFile ~/Documents/curso_data_analytics_andes/entorno_analitica_datos/lib/python3.13/site-packages/pandas/core/generic.py:4849, in NDFrame._drop_axis(self, labels, axis, level, errors, only_slice)\n   4847         new_axis = axis.drop(labels, level=level, errors=errors)\n   4848     else:\n-&gt; 4849         new_axis = axis.drop(labels, errors=errors)\n   4850     indexer = axis.get_indexer(new_axis)\n   4852 # Case for non-unique axis\n   4853 else:\n\nFile ~/Documents/curso_data_analytics_andes/entorno_analitica_datos/lib/python3.13/site-packages/pandas/core/indexes/base.py:7136, in Index.drop(self, labels, errors)\n   7134 if mask.any():\n   7135     if errors != \"ignore\":\n-&gt; 7136         raise KeyError(f\"{labels[mask].tolist()} not found in axis\")\n   7137     indexer = indexer[~mask]\n   7138 return self.delete(indexer)\n\nKeyError: \"['Columna1'] not found in axis\"",
    "crumbs": [
      "Sesiones",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sesión 2: Transformación  y aseguramiento de calidad</span>"
    ]
  },
  {
    "objectID": "Taller_2/practica2_Ecopetrol_v1.html#transformación-de-formatos-de-variables",
    "href": "Taller_2/practica2_Ecopetrol_v1.html#transformación-de-formatos-de-variables",
    "title": "Sesión 2: Transformación y aseguramiento de calidad",
    "section": "Transformación de formatos de variables",
    "text": "Transformación de formatos de variables\n\n##### Cambio de formato de una variable\ndata[\"V5\"]=data[\"V5\"].astype(float)  \n\n##### formatos que se puede utilizar\n##### int / int64 - convierte a enteros\n##### float / float64 - convierte a Números decimales\n##### int32 /  float32 - versiones de menor precisión\n##### 'Int64' - (con mayúscula) convierte a enteros que permiten nulos (nullable)\n##### 'str' - convierte a texto\n##### data['col'] = pd.to_datetime(data['col']) convierte a fecha\n\n##### Hacer varios cambios de formato a la vez\ndata = data.astype({\n    'edad': 'int',\n    'ingresos': 'float',\n    'genero': 'category'\n})\n\n#### Transformación de variables en formato datetime\n# Extraer el mes\ndata['mes'] = data['fecha a transformar'].dt.month\n\n# Extrae el año\ndata['año'] = data['fecha a transformar'].dt.year",
    "crumbs": [
      "Sesiones",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sesión 2: Transformación  y aseguramiento de calidad</span>"
    ]
  },
  {
    "objectID": "Taller_2/practica2_Ecopetrol_v1.html#cómo-guardar-dataframes-en-formato-csv-o-excel",
    "href": "Taller_2/practica2_Ecopetrol_v1.html#cómo-guardar-dataframes-en-formato-csv-o-excel",
    "title": "Sesión 2: Transformación y aseguramiento de calidad",
    "section": "Cómo guardar dataframes en formato CSV o excel",
    "text": "Cómo guardar dataframes en formato CSV o excel\n\ndata.to_csv('file_name.csv', index=False)\n\n\ndata.to_excel('file_name.xlsx', index=False)",
    "crumbs": [
      "Sesiones",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sesión 2: Transformación  y aseguramiento de calidad</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análisis Exploratorio de Datos en Python",
    "section": "",
    "text": "Introducción",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "index.html#sesión-1-analítica-descriptiva-de-datos",
    "href": "index.html#sesión-1-analítica-descriptiva-de-datos",
    "title": "Análisis Exploratorio de Datos en Python",
    "section": "Sesión 1 : Analítica descriptiva de datos",
    "text": "Sesión 1 : Analítica descriptiva de datos",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "index.html#sesión-2-transformación-y-aseguramiento-de-calidad",
    "href": "index.html#sesión-2-transformación-y-aseguramiento-de-calidad",
    "title": "Análisis Exploratorio de Datos en Python",
    "section": "Sesión 2: Transformación y aseguramiento de calidad",
    "text": "Sesión 2: Transformación y aseguramiento de calidad",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "index.html#ecopetrol---universidad-de-los-andes",
    "href": "index.html#ecopetrol---universidad-de-los-andes",
    "title": "Análisis Exploratorio de Datos en Python",
    "section": "Ecopetrol - Universidad de los Andes",
    "text": "Ecopetrol - Universidad de los Andes",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "Taller_2/ReadMe.html",
    "href": "Taller_2/ReadMe.html",
    "title": "Readme",
    "section": "",
    "text": "About Dataset\nMicrosoft Azure Predictive Maintenance https://www.kaggle.com/datasets/arnabbiswas1/microsoft-azure-predictive-maintenance/data\nContext\nThis an example data source which can be used for Predictive Maintenance Model Building. It consists of the following data:\nMachine conditions and usage: The operating conditions of a machine e.g. data collected from sensors. Failure history: The failure history of a machine or component within the machine. Maintenance history: The repair history of a machine, e.g. error codes, previous maintenance activities or component replacements. Machine features: The features of a machine, e.g. engine size, make and model, location.\nDetails\nTelemetry Time Series Data (PdM_telemetry.csv): It consists of hourly average of voltage, rotation, pressure, vibration collected from 100 machines for the year 2015.\nError (PdM_errors.csv): These are errors encountered by the machines while in operating condition. Since, these errors don’t shut down the machines, these are not considered as failures. The error date and times are rounded to the closest hour since the telemetry data is collected at an hourly rate.\nMaintenance (PdM_maint.csv): If a component of a machine is replaced, that is captured as a record in this table. Components are replaced under two situations: 1. During the regular scheduled visit, the technician replaced it (Proactive Maintenance) 2. A component breaks down and then the technician does an unscheduled maintenance to replace the component (Reactive Maintenance). This is considered as a failure and corresponding data is captured under Failures. Maintenance data has both 2014 and 2015 records. This data is rounded to the closest hour since the telemetry data is collected at an hourly rate.\nFailures (PdM_failures.csv): Each record represents replacement of a component due to failure. This data is a subset of Maintenance data. This data is rounded to the closest hour since the telemetry data is collected at an hourly rate.\nMetadata of Machines (PdM_Machines.csv): Model type & age of the Machines.",
    "crumbs": [
      "Sesiones",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Readme</span>"
    ]
  },
  {
    "objectID": "Taller_3/practica3_Ecopetrol.html",
    "href": "Taller_3/practica3_Ecopetrol.html",
    "title": "Sesión 3: Analítica avanzada",
    "section": "",
    "text": "Preparación del ambiente de trabajo\nEsta práctica se realizará sobre los datos obtenidos de la página https://www.kaggle.com  Antes de iniciar acceda al archivo ReadMe.txt disponible en la carpeta y revise la descripción de los datos a trabajar en la sesión.",
    "crumbs": [
      "Sesiones",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Sesión 3: Analítica avanzada</span>"
    ]
  },
  {
    "objectID": "Taller_3/practica3_Ecopetrol.html#entramos-al-análisis-de-los-datos",
    "href": "Taller_3/practica3_Ecopetrol.html#entramos-al-análisis-de-los-datos",
    "title": "Sesión 3: Analítica avanzada",
    "section": "Entramos al análisis de los datos",
    "text": "Entramos al análisis de los datos\n\n# Relación entre variables categóricas y continuas\ntabla=df_analitica.pivot_table(values='rotate',columns='model',aggfunc=['mean', 'std']).round(2)\ntabla_final = tabla.stack(level=1, future_stack=True).reset_index()\nprint(tabla_final)\n\n  level_0   model    mean    std\n0  rotate  model1  446.22  53.05\n1  rotate  model2  446.73  52.57\n2  rotate  model3  446.47  52.73\n3  rotate  model4  446.63  52.65\n\n\n\ndf_analitica[['vibration', 'rotate']].corr().head()\n\n\n\n\n\n\n\n\nvibration\nrotate\n\n\n\n\nvibration\n1.000000\n-0.003831\n\n\nrotate\n-0.003831\n1.000000\n\n\n\n\n\n\n\n\n#Análisis de correlación de Pearson\ncorrelacion_pearson = df_analitica[['vibration', 'rotate']].dropna().corr(method='pearson').iloc[0, 1]\nprint(correlacion_pearson)\n\n-0.0038308900924815437\n\n\n\n#Análisis de correlación de Spearman\ncorrelacion_spearman = df_analitica[['vibration', 'rotate']].dropna().corr(method='spearman').iloc[0, 1]\nprint(correlacion_spearman)\n\n-0.003300164190148436\n\n\n\n# Gráficos de dispersión - Scatterplots\n\n%matplotlib inline\n\nsns.scatterplot(data=df_analitica, x='rotate', y='vibration')\nplt.title('Gráfico de dispersión Rotate vs Vibration')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Gráficos de dispersión - Scatterplots\n\n%matplotlib inline\n\nsns.scatterplot(data=df_analitica, x='rotate', y='vibration' , hue='model')\nplt.title('Rotate Vs Vibration - Puntos coloreados por Model')\nplt.legend(loc='upper right', title='Categoría') \nplt.show()\n\n\n\n\n\n\n\n\n\ndf_analitica.dtypes\n\ndatetime      object\nmachineID      int64\nvolt         float64\nrotate       float64\npressure     float64\nvibration    float64\nfailure       object\nmodel         object\nage            int64\nMantein       object\ndtype: object\n\n\n\n# Pruebas Chi2\nfrom scipy.stats import chi2\nfrom scipy.stats import chi2_contingency\n\n# Crear tabla de contingencia con etiquetas\ntabla = pd.crosstab(df_analitica['Mantein'], df_analitica['model'])\n\n# Aplicar prueba de chi-cuadrado\nchi2, p, dof, expected = chi2_contingency(tabla)\n\n# Convertir expected a DataFrame con las mismas etiquetas que tabla original\nexpected_df = pd.DataFrame(expected, index=tabla.index, columns=tabla.columns)\n\n# Mostrar resultados\nprint(\"📊 Frecuencias Observadas (model vs mantein):\")\nprint(tabla)\n\nprint(\"\\n📈 Frecuencias Esperadas (model vs mantein):\")\nprint(expected_df)\n\nprint(\"\\n📐 Resultados de la prueba chi-cuadrado:\")\nprint(f\"  - Estadístico χ²: {chi2:.4f}\")\nprint(f\"  - Valor p: {p:.4f} - Menor a 0,05 se rechaza Ho: No existe asociación entre las variables\")\nprint(f\"  - Grados de libertad: {dof}\")\n\n\n📊 Frecuencias Observadas (model vs mantein):\nmodel    model1  model2  model3  model4\nMantein                                \ncomp1      2712    2952    5834    5820\ncomp2      2959    3192    7279    5484\ncomp3      2880    2760    6175    5449\ncomp4      3025    3168    5832    5586\n\n📈 Frecuencias Esperadas (model vs mantein):\nmodel         model1       model2       model3       model4\nMantein                                                    \ncomp1    2819.316917  2940.116951  6117.937193  5440.628939\ncomp2    3079.140788  3211.073565  6681.756789  5942.028858\ncomp3    2810.525884  2930.949246  6098.860590  5423.664281\ncomp4    2867.016412  2989.860239  6221.445427  5532.677922\n\n📐 Resultados de la prueba chi-cuadrado:\n  - Estadístico χ²: 194.2235\n  - Valor p: 0.0000 - Menor a 0,05 se rechaza Ho: No existe asociación entre las variables\n  - Grados de libertad: 9\n\n\n\n# Análisis de Varianza - ANOVA\nfrom scipy.stats import f_oneway\n\n# Agrupar los valores de v1 por cada categoría de model\ngrupos = [grupo['rotate'].values for nombre, grupo in df_analitica.groupby('model')]\n\n# Aplicar ANOVA de una vía\nf_stat, p_valor = f_oneway(*grupos)\n\n# Mostrar resultados\nprint(\"📊 Resultados del ANOVA:\")\nprint(f\"  - Estadístico F: {f_stat:.4f}\")\nprint(f\"  - Valor p: {p_valor:.4f}\")\n\n# Interpretación básica\nif p_valor &lt; 0.05:\n    print(\"❗ Rechazamos la hipótesis nula - Ho: No hay diferencias significativas entre los grupos de model.\")\nelse:\n    print(\"✅ No se rechaza la hipótesis nula Ho\")\n\n📊 Resultados del ANOVA:\n  - Estadístico F: 2.8898\n  - Valor p: 0.0340\n❗ Rechazamos la hipótesis nula - Ho: No hay diferencias significativas entre los grupos de model.\n\n\n\n# Regresión lineal\nimport statsmodels.api as sm\n\n# Elimina valores faltantes en las variables\ndata_limpia = df_analitica.dropna(subset=['rotate', 'pressure', 'vibration', 'volt'])\n\n# Definir variables independientes (X) y dependiente (Y)\nX = data_limpia[['rotate', 'pressure', 'vibration']] #variables independientes o explictivas\ny = data_limpia['volt']  #variable dependiente o repuesta \n\n# Agregar constante (intercepto)\nX = sm.add_constant(X)\n\n# Ajustar el modelo de regresión\nmodelo = sm.OLS(y, X).fit()\n\n# Mostrar resumen del modelo\nprint(modelo.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   volt   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     4.255\nDate:                Thu, 24 Jul 2025   Prob (F-statistic):            0.00517\nTime:                        10:42:09   Log-Likelihood:            -3.7265e+06\nNo. Observations:              895480   AIC:                         7.453e+06\nDf Residuals:                  895476   BIC:                         7.453e+06\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst        170.4583      0.239    712.319      0.000     169.989     170.927\nrotate        -0.0005      0.000     -1.756      0.079      -0.001    6.35e-05\npressure       0.0028      0.001      1.888      0.059      -0.000       0.006\nvibration      0.0075      0.003      2.461      0.014       0.002       0.013\n==============================================================================\nOmnibus:                     1724.902   Durbin-Watson:                   1.829\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             1792.478\nSkew:                           0.091   Prob(JB):                         0.00\nKurtosis:                       3.123   Cond. No.                     6.74e+03\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 6.74e+03. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\n\n\nfrom sklearn.cluster import KMeans\n\ndf = df_telemetry.drop(columns=['datetime'])\n\n# Clusterización método de k-medias\n# Número de clusters deseado (por ejemplo, k=3)\nkmeans = KMeans(n_clusters=5, random_state=42)\n\n# Ajustar el modelo\nkmeans.fit(df)\n\n# Asignación de etiquetas\ndf['cluster'] = kmeans.labels_\n\ndf.dtypes\n\nmachineID      int64\nvolt         float64\nrotate       float64\npressure     float64\nvibration    float64\ncluster        int32\ndtype: object\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\nmachineID\nvolt\nrotate\npressure\nvibration\ncluster\n\n\n\n\n0\n1\n176.217853\n418.504078\n113.077935\n45.087686\n2\n\n\n1\n1\n162.879223\n402.747490\n95.460525\n43.413973\n2\n\n\n2\n1\n170.989902\n527.349825\n75.237905\n34.178847\n0\n\n\n3\n1\n162.462833\n346.149335\n109.248561\n41.122144\n4\n\n\n4\n1\n157.610021\n435.376873\n111.886648\n25.990511\n2\n\n\n\n\n\n\n\n\n# Contamos cuantos registros quedaron en cada Grupo\nfrecuencia_Grupos = df['cluster'].value_counts().to_frame()\nfrecuencia_Grupos\n\n\n\n\n\n\n\n\ncount\n\n\ncluster\n\n\n\n\n\n2\n233143\n\n\n3\n185447\n\n\n1\n184130\n\n\n0\n142665\n\n\n4\n130715\n\n\n\n\n\n\n\n\n# Estandarización de variables\nfrom sklearn.preprocessing import StandardScaler\n\n# Lista de columnas continuas a estandarizar\nvariables_continuas = ['rotate', 'pressure', 'vibration']\n\n# Inicializa y ajusta el escalador\nscaler = StandardScaler()\ndata_limpia[variables_continuas] = scaler.fit_transform(data_limpia[variables_continuas])\n\n\ndata_limpia.head(5)\n\n\n\n\n\n\n\n\ndatetime\nmachineID\nvolt\nrotate\npressure\nvibration\nfailure\nmodel\nage\nMantein\n\n\n\n\n0\n2015-01-01\n1\n176.217853\n-0.531367\n1.103035\n0.874285\nNaN\nmodel3\n18\nNaN\n\n\n1\n2015-01-01\n1\n162.879223\n-0.830185\n-0.488977\n0.562805\nNaN\nmodel3\n18\nNaN\n\n\n2\n2015-01-01\n1\n170.989902\n1.532850\n-2.316411\n-1.155860\nNaN\nmodel3\n18\nNaN\n\n\n3\n2015-01-01\n1\n162.462833\n-1.903547\n0.756991\n0.136294\nNaN\nmodel3\n18\nNaN\n\n\n4\n2015-01-01\n1\n157.610021\n-0.211381\n0.995384\n-2.679717\nNaN\nmodel3\n18\nNaN",
    "crumbs": [
      "Sesiones",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Sesión 3: Analítica avanzada</span>"
    ]
  }
]